Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Due Date,Votes,Labels,Labels,Labels,Labels,Description,Environment,Log Work,Log Work,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocker),Outward issue link (Duplicate),Outward issue link (Reference),Outward issue link (Reference),Attachment,Attachment,Attachment,Custom field (Affects version (Component)),Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Date of First Response),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Estimated Complexity),Custom field (Evidence Of Open Source Adoption),Custom field (Evidence Of Registration),Custom field (Evidence Of Use On World Wide Web),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Fix version (Component)),Custom field (Flags),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Level of effort),Custom field (Machine Readable Info),Custom field (New-TLP-TLPName),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Review Date),Custom field (Reviewer),Custom field (Severity),Custom field (Severity),Custom field (Skill Level),Custom field (Skill Level),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Tags),Custom field (Test and Documentation Plan),Custom field (Testcase included),Custom field (Tester),Custom field (Workaround),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
KolmogorovSmirnovTest#exactP value is incorrect in 3.6.1 potential bug,MATH-1502,13265092,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,,,ethanmoon,ethanmoon,29/Oct/19 17:21,11/Feb/20 00:52,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"I believe that I have found a bug in the calculation of the exactP value in KolmogorovSmirnovTest.java in version 3.6.1.
 
In version 3.4.1 KolmogorovSmirnovTest#exactP(0.5633587786259542, 3, 3, true) = 0.6
 
Where as
 
In version 3.6.1 KolmogorovSmirnovTest#exactP(0.5633587786259542, 3, 3, true) = 0.09999999999999998
 
 
The approximateP value has stayed the same at ~=0.72. This seems to correspond with the change in methods of calculation in e38bbb9f4191d0d21dea0ba31fdc131b97a5597b
 
[https://github.com/apache/commons-math/commit/e38bbb9f4191d0d21dea0ba31fdc131b97a5597b#diff-34100572fcc8e6537bc7445a0e82b900]
 ",,,,,,,,,,,,,,,,,"30/Oct/19 22:19;erans;exact_vs_approximate.png;https://issues.apache.org/jira/secure/attachment/12984424/exact_vs_approximate.png",,,,1.0,,,,,,,,,,,,,,,,,,,,2019-10-30 22:27:22.645,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 11 00:52:37 UTC 2020,,,,,,,"0|z08268:",9223372036854775807,,,,,,,,,,,,,,,,"30/Oct/19 22:27;erans;The attached plot shows that the {{exactP}} function drops sharply around 0.55; this would explain why alternative implementations produce either 0.6 or 0.1 for points around that value.","30/Oct/19 22:36;ethanmoon;That makes sense. I'm not too familiar with the KolmogorovSmirnovTest; when I was upgrading math3 from 3.4.1 -> 3.6.1 one of our unit tests broke that asserted the value of the above function should be 0.6. If this is just a matter a semi-discontinuity that makes sense it just gave me a scare that value changed so sharply.

So just to be clear this is not a bug. If so I'll update the unit tests when performing the next update","30/Oct/19 23:48;erans;bq. I'm not too familiar with the KolmogorovSmirnovTest

I'm not either.
Hopefully, the set of existing tests ensure correct behaviour.  But additional test are welcome (to be added to the development version towards the upcoming version 4.0).","11/Feb/20 00:52;psteitz;I am sorry, but this is actually a regression in 3.6.1.  There is a bug in the way the new implementation handles d values that are not mass points of the KS distribution.  This should not effect actual tests, as tests will always return attained d values.  This has been fixed in Hipparchus [https://github.com/Hipparchus-Math/hipparchus/commit/9718fe2d2842bc9dac63a355702504794454ed63]

The Hipparchus fix also improves the exact computation algorithm to be faster and more numerically stable.  I will submit a PR to make similar changes to Commons Math if no one beats me to it.  

A simpler fix would be to just copy the normalizeD method in the Hipparchus code and recode the d values using it (leaving implementation of exactP otherwise unchanged).

 

 ",,,,,,,,,,,,,
MathInternalError - Kolmogorov Smirnov Test,MATH-1487,13238464,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,Incomplete,,lipinski.pawel,lipinski.pawel,10/Jun/19 07:45,17/Jan/20 12:10,20/Mar/20 20:34,17/Jan/20 12:10,3.6.1,,,,,,,1,,,,,"Hi,

I spotted a pesky bug in KolmogorovSmirnovTest class, in the method kolmogorovSmirnovTest.

In order to reproduce the error use arrays from attachments.

Stacktrace:
{noformat}
org.apache.commons.math3.exception.MathInternalError: illegal state: internal error, please fill a bug report at https://issues.apache.org/jira/browse/MATH
at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.fixTies(KolmogorovSmirnovTest.java:1171)
 at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.kolmogorovSmirnovTest(KolmogorovSmirnovTest.java:263)
 at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.kolmogorovSmirnovTest(KolmogorovSmirnovTest.java:290)

{noformat}
  ",,,,,,,,,,,,,,,,,"10/Jun/19 07:41;lipinski.pawel;alpha.arr;https://issues.apache.org/jira/secure/attachment/12971294/alpha.arr","10/Jun/19 07:41;lipinski.pawel;beta.arr;https://issues.apache.org/jira/secure/attachment/12971293/beta.arr",,,2.0,,,,,,,,,,,,,,,,,,,,2019-06-10 11:27:02.435,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 17 12:10:20 UTC 2020,,,,,,,"0|z03kfs:",9223372036854775807,,,,,,,,,,,,,,,,"10/Jun/19 11:27;erans;Thanks for the report, but please check that the bug is still present in the [development version of the library|https://gitbox.apache.org/repos/asf?p=commons-math.git] (you can find the latest snapshots [here|https://repository.apache.org/content/repositories/snapshots/org/apache/commons/commons-math4/4.0-SNAPSHOT/]).","11/Jun/19 09:07;lipinski.pawel;Sure, I downloaded 
{noformat}
commons-math4-4.0-20190530.195425-687-bin.tar.gz{noformat}
and I was trying to execute my test case,
{code:java}
@Test
public void testCase() throws IOException {

 double[] alpha = readToDoubleArray(""alpha.arr"");
 double[] beta = readToDoubleArray(""beta.arr"");

 KolmogorovSmirnovTest kolmogorovSmirnovTest = new KolmogorovSmirnovTest();
 kolmogorovSmirnovTest.kolmogorovSmirnovTest(alpha, beta);
}

private double[] readToDoubleArray(final String filename) throws IOException {
 return Files.readAllLines(Paths.get(""path"", ""to"", ""arrays"", filename))
 .stream()
 .mapToDouble(Double::parseDouble)
 .toArray();
}

{code}
but I faced an error
{noformat}
Error:(23, 30) java: cannot access org.apache.commons.statistics.distribution.ContinuousDistribution
 class file for org.apache.commons.statistics.distribution.ContinuousDistribution not found{noformat}
in the pom.xml from that tar.gz, I see plenty of dependencies e.g. 
{noformat}
<groupId>org.apache.commons</groupId>
<artifactId>commons-statistics-distribution</artifactId>
<version>0.1-SNAPSHOT</version> 
{noformat}
and I'm wondering how can I get those jars (they are not in the maven central).","11/Jun/19 11:04;erans;bq. I'm wondering how can I get those jars (they are not in the maven central).

They are also available from the [""nightly build""/snapshot repository|https://repository.apache.org/content/repositories/snapshots/org/apache/commons/].
We try to get to a first release of the new dependencies ([""Commons Numbers""|http://commons.apache.org/proper/commons-numbers/] and [""Commons Statistics""|http://commons.apache.org/proper/commons-statistics/])...  Please subscribe to the ""dev"" mailing list if you'd like to help. ;-)

However, the easiest option may be to check out the source ([git ""master"" branch|https://gitbox.apache.org/repos/asf?p=commons-math.git]), copy the unit test in the appropriate sub-directory of {{src/test}}, and then run
{noformat}
$ mvn test
{noformat}","27/Oct/19 12:21;erans;Is the problem still present?","17/Jan/20 10:21;chentao106;I can not reproduce this bug both in 3.6.1 and development version, by this code:
{code:java}
@Testpublic void testCase() throws IOException
{ double[] alpha = readToDoubleArray(""alpha.arr""); double[] beta = readToDoubleArray(""beta.arr""); KolmogorovSmirnovTest kolmogorovSmirnovTest = new KolmogorovSmirnovTest(); kolmogorovSmirnovTest.kolmogorovSmirnovTest(alpha, beta); }
private double[] readToDoubleArray(final String filename) throws IOException
{ return Files.readAllLines(Paths.get(""path"", ""to"", ""arrays"", filename)) .stream() .mapToDouble(Double::parseDouble) .toArray(); }
{code}
More information should be provide.","17/Jan/20 12:10;erans;Closing (no feedback from the OP in more than 6 months).",,,,,,,,,,,
EmpiricalDistribution:inverseCumulativeProbability return Infinity,MATH-1462,13165297,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,,,ebilarbi,ebilarbi,11/Jun/18 10:58,27/Oct/19 12:23,20/Mar/20 20:34,,3.6.1,,,,,,,1,,,,,"Hi,

inverseCumulativeProbability(0.5) return ""infinity"" which is absurd while it return correct values for 0.499999 and 0.511111, Here is the test :
{code:java}
double[] data = {6464.0205, 6449.1328, 6489.4569, 6497.5533, 6251.6487, 6252.6513, 6339.7883,
6356.2622, 6222.1251, 6157.3813, 6242.4741, 6332.5347, 6468.0633, 6471.2319, 6473.9929, 6589.1322, 
6511.2191, 6339.4349, 6307.7735, 6288.0915, 6354.0572, 6385.8283, 6325.3756, 6433.1699, 6433.6507, 
6424.6806, 6380.5268, 6407.6705, 6241.2198, 6230.3681, 6367.5943, 6358.4817, 6272.8039, 6269.0211, 
6312.9027, 6349.5926, 6404.0775, 6326.986, 6283.8685, 6309.9021, 6336.8554, 6389.1598, 6281.0372, 
6304.8852, 6359.2651, 6426.519, 6400.3926, 6440.6798, 6292.5812, 6398.4911, 6307.0002, 6284.2111, 6271.371, 6368.6377, 6323.3372, 6276.2155, 
6335.0117, 6319.2466, 6252.9969, 6445.2074, 6461.3944, 6384.1345};

EmpiricalDistribution ed = new EmpiricalDistribution(data.length);
ed.load(data);

double p50 = ed.inverseCumulativeProbability(0.5);
double p51 = ed.inverseCumulativeProbability(0.51111);
double p49 = ed.inverseCumulativeProbability(0.49999);

assertTrue(p51<6350);
assertTrue(p49<6341);
assertTrue(p50<7000);
{code}
 Any clue to fix this ?

 ",,,,,,,,,,,,,,,MATH-1431,MATH-1353,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-06-11 13:04:20.419,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Oct 27 12:23:32 UTC 2019,,,,,,,"0|i3uq2v:",9223372036854775807,,,,,,,,,,,,,,,,"11/Jun/18 13:04;erans;This bug might be the same as reported in the issue which I've just linked.

You are most welcome to help fix this class. ;)","19/Jul/18 09:54;Dagguh;The empty bins mentioned in -MATH-1432- MATH-1431 did not help in our case.

We managed to work around this bug by abandoning the ""within-bin"" smoothing altogether:
{code:java}
public class RoughEmpiricalDistribution extends EmpiricalDistribution {

    @Override
    protected RealDistribution getKernel(SummaryStatistics bStats) {
        return new ConstantRealDistribution(bStats.getMean());
    }
}
{code}

","19/Jul/18 10:50;erans;bq. The empty bins mentioned in MATH-1432 did not help in our case.

I guess you meant MATH-1431 (?).
A unit test (patch) showing the problem would be useful.  Do you mean that the fix mentioned in the other report is not good enough?","23/Jul/18 16:07;Dagguh;Correct, MATH-1431 fix was not good enough.
I can't directly link to an actual executable test, because our Git repo is private. I'll inline key classes in the comment. It's in Kotlin, but I hope it's readable enough.

{code}
/**
 * Represents the [quantile function](https://en.wikipedia.org/wiki/Quantile_function).
 */
class QuantileFunction {

    fun plot(
        data: Collection<Number>
    ): List<Quantile> {
        if (data.isEmpty()) {
            return emptyList()
        }
        val distribution = RoughEmpiricalDistribution(
            binCount = 1000,
            data = data.map { it.toDouble() }.toDoubleArray()
        )
        return (0..100)
            .map { percentileIndex -> percentileIndex.toDouble() / 100 }
            .map { cumulativeProbability ->
                Quantile(
                    cumulativeProbability = cumulativeProbability,
                    value = distribution.inverseCumulativeProbability(cumulativeProbability)
                )
            }
    }
}
{code}

{code}
import org.hamcrest.Matchers.*
import org.junit.Assert.assertThat
import org.junit.Test

class QuantileFunctionTest {

    @Test
    fun shouldPlotPercentile32() {
        val data = listOf(
            18054,
            17548,
            17350,
            17860,
            17827,
            17653,
            18113,
            18405,
            17746,
            17647,
            18160,
            17955,
            17705,
            17890,
            17974,
            17857,
            13287,
            18645,
            17775,
            17730,
            17996,
            18263,
            17861,
            17161,
            17717,
            18134,
            18669,
            18340,
            17221,
            18292,
            18146,
            17520,
            18207,
            17829,
            18206,
            13301,
            18257,
            17626,
            18358,
            18340,
            18320,
            17852,
            17804,
            17577,
            17718,
            18099,
            13395,
            17763,
            17911,
            17978,
            12935,
            17519,
            17550,
            18728,
            18518,
            17698,
            18739,
            18553,
            17982,
            18113,
            17974,
            17961,
            17645,
            17867,
            17890,
            17498,
            18718,
            18191,
            18177,
            17923,
            18164,
            18155,
            6212,
            5961,
            711
        )

        val quantiles = QuantileFunction().plot(data)

        val p31 = quantiles[31].value
        val p32 = quantiles[32].value
        val p33 = quantiles[33].value
        assertThat(p32, greaterThanOrEqualTo(p31))
        assertThat(p32, lessThanOrEqualTo(p33))
    }
}
{code}

{code}
/**
 * Represents a [quantile](https://en.wikipedia.org/wiki/Quantile).
 */
data class Quantile(
    val cumulativeProbability: Double,
    val value: Double
)
{code}

{code}
import org.apache.commons.math3.distribution.ConstantRealDistribution
import org.apache.commons.math3.distribution.RealDistribution
import org.apache.commons.math3.random.EmpiricalDistribution
import org.apache.commons.math3.stat.descriptive.SummaryStatistics

/**
 * Works around [MATH-1462](https://issues.apache.org/jira/browse/MATH-1462).
 */
class RoughEmpiricalDistribution(
    binCount: Int,
    data: DoubleArray
) : EmpiricalDistribution(binCount) {

    init {
        super.load(data)
    }

    override fun getKernel(
        bStats: SummaryStatistics
    ): RealDistribution {
        return ConstantRealDistribution(bStats.mean)
    }
}
{code}","27/Oct/19 12:23;erans;If the issue is still present, please attach (or make a PR with) a unit test in Java.  Thanks.",,,,,,,,,,,,
WelzlEncloser throws MathInternalError,MATH-1488,13239028,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,Won't Fix,,BenjaminKrogh,BenjaminKrogh,12/Jun/19 13:13,27/Oct/19 12:19,20/Mar/20 20:34,27/Oct/19 12:19,3.6.1,,,,,,,0,,,,,"The following code snippets throws a MathInternalError when trying to calculate the enclosing ball of the given points.
{noformat}
@Test
public void encloserTest() {
    final List<Vector2D> points = Arrays.asList(
            new Vector2D(271.59, 57.282),
            new Vector2D(269.145, 57.063),
            new Vector2D(309.117, 77.187),
            new Vector2D(316.989, 34.835),
            new Vector2D(323.101, 53.972)
    );
    double tolerance = 1;
    WelzlEncloser<Euclidean2D, Vector2D> encloser = new WelzlEncloser<>(tolerance, new DiskGenerator());
    encloser.enclose(points);
}{noformat}
Interestingly, if tolerance is set lower than 0.965 or higher than 1.100, it suceeds. I was not able to find any tolerance value between 0.965 and 1.100 that succeeds.","java 1.8, Windows 10 x64, idea",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-06-12 13:34:31.414,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Oct 27 12:19:52 UTC 2019,,,,,,,"0|z03nww:",9223372036854775807,,,,,,,,,,,,,,,,"12/Jun/19 13:34;erans;The {{geometry}} package of ""Commons Math"" is being refactored and moved to a new [""Commons Geometry"" library|http://commons.apache.org/proper/commons-geometry/].

Please check out the [source code|https://gitbox.apache.org/repos/asf?p=commons-geometry.git].
If the bug is still present, please file a report in the [corresponding JIRA project|https://issues.apache.org/jira/projects/GEOMETRY] (with a link to this report).","12/Jun/19 13:38;erans;Forgot to add: If you are a user of this functionality, you are most welcome to review and comment the new API.  Help is also [wanted|https://markmail.org/message/dcbxsjsbgtqc7525] to get closer to the first release.","12/Jun/19 14:12;BenjaminKrogh;The new library is affected too. I have made a bug report over there too.","27/Oct/19 12:19;erans;Fix is in ""Commons Geometry"".",,,,,,,,,,,,,
KS test throw MathInternalError: illegal state,MATH-1475,13226104,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,Fixed,,xuech,xuech,04/Apr/19 12:14,06/Apr/19 02:05,20/Mar/20 20:34,06/Apr/19 02:05,3.6.1,,,,,4.0,,0,,,,,"{code:java}
public class CC {
public static void main(String []args) throws Exception{
double[]x=new double[]{0.12350159883499146, -0.2601194679737091, -1.322849988937378, 0.379696249961853, 0.3987586498260498, -0.06924121081829071, -0.13951236009597778, 0.3213207423686981, 0.7949811816215515, -0.15811105072498322, 0.19912190735340118, -0.46363770961761475, -0.20019817352294922, 0.3062838613986969, -0.3872813880443573, 0.10733723640441895, 0.10910066962242126, 0.625770092010498, 0.2824835777282715, 0.3107619881629944, 0.1432388722896576, -0.08056988567113876, -0.5816712379455566, -0.09488576650619507, -0.2154506891965866, 0.2509046196937561, -0.06600788980722427, -0.01133995596319437, -0.22642627358436584, -0.12150175869464874, -0.21109570562839508, -0.17732949554920197, -0.2769380807876587, -0.3607368767261505, -0.07842907309532166, -0.2518743574619293, 0.035517483949661255, -0.6556509137153625, -0.360045850276947, -0.09371964633464813, -0.7284095883369446, -0.22719840705394745, -1.5540679693222046, -0.008972732350230217, -0.09106933325529099, -0.6465389132499695, 0.036245591938495636, 0.657580554485321, 0.32453101873397827, 0.6105462908744812, 0.25256943702697754, -0.194427490234375, 0.6238796710968018, 0.5203511118888855, -0.2708645761013031, 0.07761227339506149, 0.5315862894058228, 0.44320303201675415, 0.6283767819404602, 0.2618369162082672, 0.47253096103668213, 0.3889777660369873, 0.6856100559234619, 0.3007083833217621, 0.4963226914405823, 0.08229698985815048, 0.6170856952667236, 0.7501978874206543, 0.5744063258171082, 0.5233180522918701, 0.32654184103012085, 0.3014495372772217, 0.4082445800304413, -0.1075737327337265, -0.018864337354898453, 0.34642550349235535, 0.6414541602134705, 0.16678297519683838, 0.46028634905815125, 0.4151197075843811, 0.14407725632190704, 0.41751566529273987, -0.054958608001470566, 0.4995657801628113, 0.4485369324684143, 0.5600396990776062, 0.4098612368106842, 0.2748555839061737, 0.2562614381313324, 0.4324824810028076};
double[]y=new double[]{2.6881366763426717, 2.685469965655465, 2.261888917462379, -2.1933598759641226, -2.4279488152810145, -3.159389495849609, -2.3150004548153444, 2.468029206047388, 2.9442494682288953, 2.653360013462529, -2.1189940659194835, -2.121635289903703, -2.103092459792032, -2.737034221468073, -2.203389332350286, 2.1985949039005512, -2.5021604073154737, 2.2732754920764533, -2.3867025598454346, 2.135919387338413, 2.338120776050672, 2.2579794509726874, 2.083329059799027, -2.209733724709957, 2.297192240399189, -2.201703830825843, -3.460208691996806, 2.428839296615834, -3.2944259224581574, 2.0654875493620883, -2.743948930837782, -2.2240674680805212, -3.646366778182357, -2.12513198437294, 2.979166188824589, -2.6275491570089033, -2.3818176136461338, 2.882096356968376, -2.2147229261558334, -3.159389495849609, 2.312428759406432, 2.3313864098846477, -2.72802504046371, -2.4216068225364245, 3.0119599306499123, 2.5753099009496783, -2.9200121783556843, -2.519352725437922, -4.133932580227538, -2.30496316762808, 2.5381353678521363, 2.4818233632136697, 2.5277451177925685, -2.166465445816232, -2.1193897819471563, -2.109654332722425, 3.260211545834851, -3.9527673876059013, -2.199885089466947, 2.152573429747697, -3.1593894958496094, 2.5479522823226795, 3.342810742466116, -2.8197184957304007, -2.3407900299253765, -2.3303967152728537, 2.1760131201015565, 2.143930552944634, 2.33336231754409, 2.9126278362420575, -2.121169134387265, -2.2980208408109095, -2.285400411434817, -2.0742764640932903, 2.304178664095016, -2.2893825538911634, -3.7714771984158806, -2.7153698816026886, 2.8995011276220226, -2.158787087333056, -2.1045987952052547, 2.8478762016468147, -2.694578565956955, -2.696014432856399, -2.3190122657403496, -2.48225194403028, 3.3393947563371764, 2.7775468034263517, -3.396526561479875, -2.699967947404961};
KolmogorovSmirnovTest kst=new KolmogorovSmirnovTest();
double p=kst.kolmogorovSmirnovTest(x, y);
System.out.println(p);
}
}
{code}

Results:
run:
Exception in thread ""main"" org.apache.commons.math3.exception.MathInternalError: illegal state: internal error, please fill a bug report at https://issues.apache.org/jira/browse/MATH
at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.fixTies(KolmogorovSmirnovTest.java:1171)
at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.kolmogorovSmirnovTest(KolmogorovSmirnovTest.java:263)
at org.apache.commons.math3.stat.inference.KolmogorovSmirnovTest.kolmogorovSmirnovTest(KolmogorovSmirnovTest.java:290)
at com.snplife.common.math.CC.main(CC.java:17)
C:\Users\xuechao\AppData\Local\NetBeans\Cache\8.2\executor-snippets\run.xml:53: Java returned: 1
","Windows 10 (Professional)

JDK 8",,,,,,,,,,,,,,,,"04/Apr/19 12:19;xuech;Figure_1.png;https://issues.apache.org/jira/secure/attachment/12964859/Figure_1.png",,,,1.0,,,,,,,,,,,,,,,,,,,,2019-04-04 13:29:03.266,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Apr 06 01:58:22 UTC 2019,,,,,,,"0|z01gew:",9223372036854775807,,,,,,,,,,,,,,,,"04/Apr/19 13:29;erans;Thanks for the report.
However, please try the development version (4.0-SNAPSHOT) and let us know whether it fails too.","05/Apr/19 06:41;xuech;It fails too when I used the development version (4.0-SNAPSHOT)  with the same Exception.","05/Apr/19 06:42;xuech;It fails too when I used the development version (4.0-SNAPSHOT)  with the same Exception.","05/Apr/19 13:53;erans;Which snaphot did you use?
 In any case, please retry either with the latest snapshot from the [CI system|https://repository.apache.org/content/repositories/snapshots/org/apache/commons/commons-math4/4.0-SNAPSHOT/] or with a JAR compiled from the latest version of the [source code|https://gitbox.apache.org/repos/asf?p=commons-math.git].

On my machine, running (JDK 8), your case passed (I copied it as a unit test).","06/Apr/19 01:58;xuech;I used the snaphot in [github|[https://github.com/jcastro-inf/commons-math4]].

The problem was solved when I used the snaphot you provide. Thank you! ",,,,,,,,,,,,
Mann-Whitney U Test returns maximum of U1 and U2,MATH-1453,13141758,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,,,nikos.katsip,nikos.katsip,01/Mar/18 10:46,30/Apr/18 19:03,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"Currently, I need to use Mann-Whitney U Test and I figured out that Apache Commons Math has it implemented. After consulting the [Wiki|https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test] presented in the Java Doc, it indicates that the U statistic of this test is the minimum among U1 and U2. However, when I look into Apache Commons Math {{MannWhitneyUTest.mannWhitneyU()}} method, it returns the maximum of U1 and U2. In fact, the code of this method is the following: 

 
{code:java}
public double mannWhitneyU(double[] x, double[] y) throws NullArgumentException, NoDataException {
  this.ensureDataConformance(x, y);
  double[] z = this.concatenateSamples(x, y);
  double[] ranks = this.naturalRanking.rank(z);
  double sumRankX = 0.0D;

  for(int i = 0; i < x.length; ++i) {
    sumRankX += ranks[i];
  }

  double U1 = sumRankX - (double)((long)x.length * (long)(x.length + 1) / 2L);
  double U2 = (double)((long)x.length * (long)y.length) - U1;
  return FastMath.max(U1, U2);
}
{code}
Also, in the Java Doc it is stated that the maximum value of U1 and U2 is returned.

 
My question is why Apache Commons returns the maximum of those two values, whereas all other sources I found online indicate returning the minimum? If this is not wrong, then shouldn't the Java Doc be updated to include a source that justifies that the maximum U should be returned.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-03-01 12:00:05.253,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Apr 30 19:03:31 UTC 2018,,,,,,,"0|i3qqkf:",9223372036854775807,,,,,,,,,,,,,,,,"01/Mar/18 12:00;erans;Thanks for your interest in this project.
We are currently looking for contributors for refactoring the {{stat}} package of ""Commons Math"". A [new project|http://commons.apache.org/proper/commons-statistics/] has been set up.

For the particular issue which you raise, a unit test showing the problem is most welcome (e.g. comparing with the value computed by another implementation on identical input).  Thanks.","30/Apr/18 19:03;psteitz;The minimum value is what should be reported as the value of the statistic.  That is in fact what is used by the code to estimate p-values.  The p-value computation also suffers from some accuracy issues.  First, no continuity correction is applied when computing the normal approximation.  Second (as noted in the javadoc), nothing is done to adjust the variance in the presence of ties in the data.   The patch applied to fix [this issue|https://github.com/Hipparchus-Math/hipparchus/issues/38] in Hipparchus could be fairly easily backported to current [math] code.  The patch there also includes exact computation of p-values for very small samples.  Patches welcome there too, of course.",,,,,,,,,,,,,,,
"FastMath.exp() generates java.lang.ArrayIndexOutOfBoundsException: length=1025; index=333726400",MATH-1457,13155698,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Critical,,,R,R,27/Apr/18 12:50,27/Apr/18 12:52,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"Using Apache FastMath v3.6.1 in my Android project. The OS is Android Oreo 8.1. Got this exception:

{{java.lang.ArrayIndexOutOfBoundsException: length=1025; index=333726400}}
 {{        at org.apache.commons.math3.util.FastMath.exp(FastMath.java:936)}}
 {{        at org.apache.commons.math3.util.FastMath.exp(FastMath.java:864)}}

 

Noticed this for the first (and only) time. Most of the time the function works okay, so unable to reproduce it with some specific numbers.

 

Incriminated part of the code:

{{{color:#3f7f5f}/* Get the fractional part of x, find the greatest multiple of 2^-10 less than{color}{color:#3f7f5f} * x and look up the exp function of it.{color}{color:#3f7f5f} * fracPartA will have the upper 22 bits, fracPartB the lower 52 bits.{color}{color:#3f7f5f} */{color}}}

{{{color:#7f0055}final int {color}{color:#6a3e3e}intFrac {color}= ({color:#7f0055}int{color}) ((x - {color:#6a3e3e}intVal{color}) * {color:#0000ff}1024.0{color});}}
*_HERE ->>_*   {{{color:#7f0055}final double {color}{color:#6a3e3e}fracPartA {color}= ExpFracTable.{color:#0000c0}EXP_FRAC_TABLE_A{color}[{color:#6a3e3e}intFrac{color}];}}
 {{{color:#7f0055}final double {color}{color:#6a3e3e}fracPartB {color}= ExpFracTable.{color:#0000c0}EXP_FRAC_TABLE_B{color}[{color:#6a3e3e}intFrac{color}];}}
 {{ }}

 ",Android Oreo 8.1,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2018-04-27 12:50:11.0,,,,,,,"0|i3t3s7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DBSCAN Implementation does not count the seed point itself as part of its neighbors count,MATH-1367,12971742,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,amolsingh,amolsingh,21/May/16 05:18,07/Mar/20 15:13,20/Mar/20 20:34,,3.6.1,,,,,4.0,,2,,,,,"The DSCAN paper describes the eps-neighborhood of a point as 

https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf (Page 2)
Definition 1: (Eps-neighborhood of a point) The Eps-neighborhood of a point p, denoted by NEps(p), is defined by NEps(p) = {q ∈ D | dist(p,q)< Eps} 

in other words for all q points that are a member of database D whose distance from p is less that Eps should be classified as a neighbor. This should include the point itself. 

The implementation however has a reference check to the point itself and does not add it to its neighbors list.

private List<T> getNeighbors(final T point, final Collection<T> points) {
        final List<T> neighbors = new ArrayList<T>();
        for (final T neighbor : points) {
            if (point != neighbor && distance(neighbor, point) <= eps) {
                neighbors.add(neighbor);
            }
        }
        return neighbors;
    } 

""point != neighbor ""  check should be removed here. Keeping this check effectively is raising the minPts count by 1. Other third party QuadTree backed DBSCAN implementations consider the center point in its neighbor count E.g. bmw-carit library. 

If this is infact by design, the check should use value equality instead of reference equality. T extends Clusterable<T> , the client should be able to define this behavior. 
",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2016-05-21 08:27:01.928,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 16 04:03:27 UTC 2018,,,,,,,"0|i2ybbb:",9223372036854775807,,,,,,,,,,,,,,,,"21/May/16 08:27;erans;Hi Amol.

Thanks for your report.

From reading the problem description it is not obvious to figure out whether your proposed fix won't have any unwanted side-effects (e.g. it could be that the ""getNeighbors"" was not meant to exactly match the definition in the reference you cite; maybe you are totally right, I'm just guessing since I never looked at that code...).

Could you provide a unit test showing that it is indeed a bug (i.e. a case where the best solution cannot be recovered unless the fix is applied)?
","21/May/16 16:17;amolsingh;Hi Giles, 

Thanks for the quick response. 

Here's a simple breaking test, you should be able to add this to DBSCANClustererTest.java and run it. 

 @Test public void testBreakingCase() {
        final DoublePoint[] points = { new DoublePoint(new double[] { 21.345289965479466, 32.149537670215295 }),
                new DoublePoint(new double[] { 42.02226837841131, 19.69611946377732 }),
                new DoublePoint(new double[] { 41.930019221367985, 21.954397109962457 }),
                new DoublePoint(new double[] { 42.87345060400816, 18.796775009724836 }) };

        final DBSCANClusterer<DoublePoint> clusterer = new DBSCANClusterer<DoublePoint>(3, 3);
        List<Cluster<DoublePoint>> clusters = clusterer.cluster(Arrays.asList(points));
        Assert.assertEquals(1, clusters.size());
        final List<DoublePoint> clusterOne = Arrays.asList(points[1], points[2], points[3]);
        Assert.assertTrue(clusters.get(0).getPoints().containsAll(clusterOne));
    }

Now, if you set minPts=2 or change the code to remove the reference check of the point to itself in getNeighbors() this will pass. 

Let me know if you agree this is a bug. I'm happy to submit a patch. This change does change the behavior for existing users, the algorithm will produce more clusters / shape of clusters may change. Nonetheless I feel this would be the correct interpretation of the DBSCAN paper, and it seems consistent with other third party libraries I've evaluated.","24/May/16 12:57;erans;bq. Let me know if you agree this is a bug.

I don't know. :(

If you are positive that the algorithm was not correctly implemented, please do submit a patch with code comments that explain why the change was necessary.
It would also be nice to set up a unit test showing a practical case that this implementation agrees with the result computed by another implementation.

Thanks.","24/May/16 14:33;amolsingh;Okay, I'll do that. 

https://en.wikipedia.org/wiki/DBSCAN Not the most reliable source but if you look at the pseudocode, thats how others have interpreted this algorithm as well. 
{quote}
regionQuery(P, eps)
   return all points within P's eps-neighborhood (including P)
{quote}

I'll submit a patch. ","12/Jan/18 08:50;jiaopaner_cn;Hello,Amol
    I quite agree with your opinion .I also found this problem when I use the DBSCAN algorithm.The version I used is apache-commons -math-3.6.1.
So the problem still exists,and I also found other problems in addition to the above problem.The time complexity of the algorithm is always n^2 when I test.Besides that,there are many no necessary operations in the algorithm implementation.BTW,why only DoublePoint, no StringPoint, so I can't use Levenshtein distance to search the adjacency points.I'll create a detailed bug report .","16/Aug/18 04:03;backkom;I agree with you ",,,,,,,,,,,
Percentile computational accuracy issue,MATH-1490,13239825,Bug,Reopened,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,chtompki,lingchao,lingchao,16/Jun/19 20:17,08/Feb/20 18:01,20/Mar/20 20:33,,3.4,3.4.1,3.5,3.6,3.6.1,,,0,performance,,,,"The percentile method works well on the older versions, e.g., the version before 3.4. However, when I update commons-math to the newer version, there produces a computational accuracy issue. There is a backward compatibility bug behind it.","System: Linux testinglab 4.4.0-131-generic #157~14.04.1-Ubuntu


Java version ""1.8.0_191""
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)

 

 ",,,,,,,,,,,,STATISTICS-18,,,,"16/Jun/19 20:16;lingchao;BugDemo.java;https://issues.apache.org/jira/secure/attachment/12971913/BugDemo.java",,,,1.0,,,,,,,,,,,,,,,,,,,,2019-06-19 18:03:21.356,,,false,,,,,,,,,,Important,,,,,,,,9223372036854775807,,,Sat Aug 24 12:37:09 UTC 2019,,,,,,,"0|z03st4:",9223372036854775807,,,,,,,,,,,,,,,,"19/Jun/19 18:03;virendrasinghrp;The Test case given by you in *#MATH-1491* can be resolved  using delta value *1e-15* but, it is not working in this case!

This is the error I found:

{color:#ff0000}_java.lang.AssertionError: expected:<68.95> but was:<68.94999999999999>_{color}

{color:#333333}*1e-14* should work in this case, but it's not working. While *1e-13* is working{color}","20/Jun/19 17:12;chtompki;I think [~erans] wanted to link this over to STATISTICS-7 too.","20/Jun/19 17:24;chtompki;Test case is different.","22/Jun/19 00:56;erans;bq. There is a backward compatibility bug behind it.

Could you please be more explicit?
What is the expected output?","24/Jun/19 17:33;lingchao;Hi Gilles,

For this test cast, my expected output is 68.95. It works well on the version before 3.4. When I updated the commons-math version to 3.5 or newer version. The output changed to 68.94999999999999.","25/Jun/19 00:24;erans;bq. my expected output is 68.95.

With what precision?","23/Aug/19 16:38;lingchao;Hi Gilles,

 

The output is different when I update it, and it breaks my existing code. I got an incompatible error.

 

Thanks.","23/Aug/19 23:38;erans;Did the CM code change (from when it produced your expected to when it doesn't anymore)?","23/Aug/19 23:44;lingchao;No. I didn't change any code. I just upgrade the commons-math. ","24/Aug/19 00:12;erans;I'm asking that you please check whether the _Commons_ _Math_ (CM) code was modified by the developers team, i.e. the code which you _call_ (to get the number ""68.95"").
","24/Aug/19 12:37;erans;I've done it. So:
{noformat}
$ git diff MATH_3_3 MATH_3_4 -- src/main/java/org/apache/commons/math3/stat/descriptive/rank/Percentile.java
{noformat}
displays a large number of changes between v3.3 and v3.4 (in order to add new features).
 I'm not too surprised that this could entail a 1e-15 relative change of the output. Moreover, the unit tests show an expected level of precision much lower than that (although I admit that it's not clear why).
{quote}it breaks my existing code. I got an incompatible error.
{quote}
Could you elaborate a little?",,,,,,
Barycenter of a clockwise SphericalPolygonsSet is incorrect.,MATH-1507,13275809,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,balsingh,balsingh,20/Dec/19 21:09,15/Jan/20 21:55,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"Let's say there is a circle on a spherical surface.
 * The circle center is given by S2Point(theta=-0.6981, phi=0.87266). The radius is irrelevant.
 * Let's discretize this circle into a polygon with 100 edges. Let's make the orientation {color:#ff0000}clockwise{color}.
 * Since its a clockwise circle, from symmetry, we know that the barycenter would be around S2Point(theta=2.44346, phi=2.268928), which is just the reverse of the normal vector at the circle center.
 * Using SphericalPolygonsSet, the calculated barycenter is S2Point(theta=2.4922, phi=0.69889).

 

A few things I've already tested:
 * For counterclockwise, the result is correct.
 * The perimeter and surface area of the polygon is correct for both counterclockwise and clockwise.
 * The SphericalPolygonsSet barycenter seems to be a function of the circle radius. From symmetry, we know that there should be no dependence on the circle radius.
 * The theta is kind of close. However, the phi is off about pi/2.

 

 

 

 ",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-12-20 23:51:43.517,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 07 15:27:07 UTC 2020,,,,,,,"0|z09wb4:",9223372036854775807,,,,,,,,,,,,,,,,"20/Dec/19 23:51;erans;Please test this with [""Commons Geometry""|https://gitbox.apache.org/repos/asf?p=commons-geometry.git].
 If the issue still exists, you should move this report to the [dedicated JIRA project|https://issues.apache.org/jira/projects/GEOMETRY].","03/Jan/20 15:42;balsingh;When is the expected release of commons-geometry? I can't upgrade until that library is released.","03/Jan/20 17:37;erans;Upgrade which dependency?  Are you developing a software that will depend on ""commons-geometry""?
Anyways, this is a question for the ""dev"" ML.  Please post it there.  Thanks.","07/Jan/20 15:27;balsingh;This is also failing in commons-geometry. See [https://github.com/apache/commons-geometry/pull/51]",,,,,,,,,,,,,
"Rotation(double[][], double) constructs inverse quaternion due to bug in mat2quat",MATH-1400,13032903,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Won't Fix,,rhuitl,rhuitl,08/Jan/17 20:09,02/Dec/19 07:51,20/Mar/20 20:34,02/Dec/19 07:51,3.6.1,,,,,4.0,,0,,,,,"Constructing a Rotation object from a rotation matrix and extracting the quaternion gives the *inverse* of the expected quaternion.

E.g. something like this:
{code}
Rotation rot = new Rotation(Array2DRowRealMatrix(matrixData).getData())
Quaternion q = new Quaternion(rot.getQ0(), rot.getQ1(), rot.getQ2(), rot.getQ3());
{code}

results in q being the inverse of what is expected.

I tracked this down to Rotation#mat2quat(final double[][]) which seems to access the matrix elements as if they were stored transposed. E.g. compare with Quat4f#set(Matrix3f):

{code:title=Rotation.java}
quat[1] = inv * (ort[1][2] - ort[2][1]);
quat[2] = inv * (ort[2][0] - ort[0][2]);
quat[3] = inv * (ort[0][1] - ort[1][0]); // <-- m01 - m10
{code}

{code:title=Quat4f.java}
this.x = (m1.m21 - m1.m12) * ww;
this.y = (m1.m02 - m1.m20) * ww;
this.z = (m1.m10 - m1.m01) * ww; // <-- m10 - m01
{code}

I compared the result from Commons Math with JavaFX, JavaX Vecmath and NumPy + http://www.lfd.uci.edu/~gohlke/code/transformations.py.html. All but Commons Math agree on the result.

You can find my test program here: http://pastebin.com/jxwFi9mt
It prints the following output (Python results added manually):

{noformat}
[ 0.7  0.0  0.0 -0.7] (Commons Math)
[ 0.7  0.0  0.0  0.7] (JavaFX)
[ 0.7  0.0  0.0  0.7] (JavaX Vecmath)
[ 0.7  0.0  0.0  0.7] (NumPy + transformations.py)

[-0.2  1.0  0.0  0.0] (Commons Math)
[ 0.2  1.0  0.0  0.0] (JavaFX)
[ 0.2  1.0  0.0  0.0] (JavaX Vecmath)
[ 0.2  1.0  0.0  0.0] (NumPy + transformations.py)

[ 0.2  0.0  1.0  0.0] (Commons Math)
[ 0.2  0.0 -1.0  0.0] (JavaFX)
[ 0.2  0.0 -1.0  0.0] (JavaX Vecmath)
[-0.2  0.0  1.0  0.0] (NumPy + transformations.py)

[-0.2  0.0  0.0  1.0] (Commons Math)
[ 0.2  0.0  0.0  1.0] (JavaFX)
[ 0.2  0.0  0.0  1.0] (JavaX Vecmath)
[ 0.2  0.0  0.0  1.0] (NumPy + transformations.py)
{noformat}

The other constructor using mat2quat() is probably also affected although I did not verify this.
",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-01-10 00:17:26.093,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 02 07:51:35 UTC 2019,,,,,,,"0|i38eyv:",9223372036854775807,,,,,,,,,,,,,,,,"10/Jan/17 00:17;erans;Thanks for the thorough report.

Unfortunately, the Commons Math project is in dire need of maintainers.
For a few months, we've been (very slowly) moving some of the functionality over to new, smaller, components (""random number generation"" was completed, ""complex"" is under way).
The ""geometry"" package (from the ""master"" branch in the source code repository) is another very good candidate, as it is almost self-contained (few dependencies on other parts of the library).

Help is most welcome.
Please join the ""dev"" ML of the ""Commons"" project for more information.","12/Apr/17 09:53;erans;This bug report should be copied to [NUMBERS|https://issues.apache.org/jira/browse/NUMBERS] since the the {{Quaternion}} has been moved to the {{commons-numbers-quaternion}} module.","03/May/17 07:45;kinow;[~erans] should we move the issue, or leave this one here as Won't Fix, and open a new one under NUMBERS for it??? I can do either way tomorrow, just let me know which way you prefer (I normally move issues, but I recall we doing something else some time ago... for an issue with reciprocal method?)","03/May/17 09:58;erans;Issue was copied to NUMBERS, but the discussion there indicates that MATH may actually be the right place for this functionality.","02/Dec/19 07:51;erans;Class {{Rotation}} was removed from ""Commons Math"" (see MATH-1469).  Codes were ported to [""Commons Geometry""|http://commons.apache.org/geometry] (and refactored there).",,,,,,,,,,,,
An error in Gamma.java,MATH-1496,13254204,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Won't Fix,,cxfustc,cxfustc,02/Sep/19 10:00,02/Sep/19 10:54,20/Mar/20 20:34,02/Sep/19 10:54,3.6.1,,,,,,,0,,,,,"{noformat}
if (x >= C_LIMIT) {
      // use method 4 (accurate to O(1/x^8)
      double inv = 1 / (x * x);
      // ...
      return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) + inv * (1.0 / 120 - inv / 252));
}
{noformat}
Line 463:
{code}
 return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) + inv * (1.0 / 120 - inv / 252));
{code}
Is it should be:
{code}
 return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) - inv * (1.0 / 120 - inv / 252));
{code}",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-09-02 10:44:12.863,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 02 10:54:01 UTC 2019,,,,,,,"0|z068qg:",9223372036854775807,,,,,,,,,,,,,,,,"02/Sep/19 10:44;erans;Thanks for th report.
 You are quite right; but this has already been [fixed|https://gitbox.apache.org/repos/asf?p=commons-numbers.git;a=commit;h=14f6f851b179249cb74b6dfa5b3c8d193e607186] in the new [""Commons Numbers""|http://commons.apache.org/proper/commons-numbers/] project into which the [Gamma functionality has been moved|https://gitbox.apache.org/repos/asf?p=commons-numbers.git;a=tree;f=commons-numbers-gamma].","02/Sep/19 10:54;erans;Class does not exist anymore in the development version (4.0-SNAPSHOT) of Commons Math.
Fix was applied in the replacement code that is now in the Commons Numbers project (see previous comment).",,,,,,,,,,,,,,,
"Eigendecomposition Float comparison with ==; this is bad",MATH-1493,13242839,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,Friedrich,Friedrich,02/Jul/19 20:32,02/Jul/19 21:19,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"If you compare two float numbers you should not use ==. I think this lead to some arithmetik mistakes. Maybe you should use epsilon comparison so not x == 0 but

x < 0.00000000000001

 

 

Effected methods:

findEigenVectors;

row 671

if (e[i + 1] == 0.0) {

row 687

if (t == 0.0 && i >= j) 

 

isNonSingular(); row 522

largestEigenvalueNorm == 0.0

 

 ","I use very small and very big float numbers and number which are very near to 0.0 like -10^30;
so this effect me.",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-07-02 21:19:58.622,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 02 21:19:58 UTC 2019,,,,,,,"0|z04bdc:",9223372036854775807,,,,,,,,,,,,,,,,"02/Jul/19 21:19;erans;You might be pointing to bugs, but the construct could also be intentional.
This is very old code, and it would be dangerous to change it without a demonstrated failure.
Unit tests are most welcome.",,,,,,,,,,,,,,,,
Percentile computational accuracy issue,MATH-1491,13239826,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,lingchao,lingchao,16/Jun/19 20:31,20/Jun/19 19:33,20/Mar/20 20:34,,3.4,3.4.1,3.5,3.6,3.6.1,,,0,performance,,,,"Hi, 

The percentile method works well on the older versions, e.g., the version before 3.4. However, when I update commons-math to the newer version, there produces a computational accuracy issue. There is a backward compatibility bug behind it.
","System: Linux testinglab 4.4.0-131-generic #157~14.04.1-Ubuntu


Java version ""1.8.0_191""
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)

 

 ",,,,,,,,,,,,STATISTICS-18,,MATH-1490,,"16/Jun/19 20:31;lingchao;BugDemo.java;https://issues.apache.org/jira/secure/attachment/12971914/BugDemo.java",,,,1.0,,,,,,,,,,,,,,,,,,,,2019-06-19 17:47:09.355,,,false,,,,,,,,,,Important,,,,,,,,9223372036854775807,,,Thu Jun 20 17:13:38 UTC 2019,,,,,,,"0|z03stc:",9223372036854775807,,,,,,,,,,,,,,,,"19/Jun/19 17:47;virendrasinghrp;Hi [~lingchao], I looked into your issue, I checked it on version 2.2 & 3.6 with your Test case. I found that version 2.2 gives the Percentile value = *7.55* while the version 3.6 gives the Percentile value = *7.550000000000001*(for this particular test case).

It can be solved if you add delta/tolerance *1e-15* in assertEquals(expected,actual,delta) method.","20/Jun/19 17:13;chtompki;I meant to link this one [~erans], to STATISTICS-7",,,,,,,,,,,,,,,
Exception at IntervalUtils.getClopperPearsonInterval,MATH-1401,13037603,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,kinow,art.g,art.g,25/Jan/17 07:38,18/Apr/19 15:46,20/Mar/20 20:34,16/Apr/19 11:01,3.6.1,,,,,4.0,,0,,,,,"IntervalUtils.getClopperPearsonInterval throws an exception when number of successes equals to zero or number of successes = number of trials.

IntervalUtils.getClopperPearsonInterval(1, 0, 0.95) or IntervalUtils.getClopperPearsonInterval(1, 1, 0.95) throws org.apache.commons.math3.exception.NotStrictlyPositiveException despite that its input parameters are valid. 



 ",,,,,,,,,,,,,,,,,"17/Apr/19 21:38;micdestefano;ClopperPearsonInterval.java;https://issues.apache.org/jira/secure/attachment/12966288/ClopperPearsonInterval.java","17/Apr/19 21:37;micdestefano;ClopperPearsonIntervalTest.java;https://issues.apache.org/jira/secure/attachment/12966287/ClopperPearsonIntervalTest.java",,,2.0,,,,,,,,,,,,,,,,,,,,2017-02-01 15:28:27.089,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Apr 18 15:46:39 UTC 2019,,,,,,,"0|i3965z:",9223372036854775807,,,,,,,,,,,,,,,,"01/Feb/17 15:28;erans;I seem to recall that it might be fixed in the current ""master"" branch.
Can you try it?  Thanks.
","03/May/17 07:11;kinow;With the latest code from master today (dff1a0953d97d46290750a46d01be1e1519ae698):

{code}
ConfidenceInterval ci = IntervalUtils.getClopperPearsonInterval(1, 0, 0.95);
{code}

Throws:

{noformat}
Exception in thread ""main"" org.apache.commons.math4.exception.MathIllegalArgumentException: lower bound (0) must be strictly less than upper bound (0)
	at org.apache.commons.math4.stat.interval.ConfidenceInterval.checkParameters(ConfidenceInterval.java:103)
	at org.apache.commons.math4.stat.interval.ConfidenceInterval.<init>(ConfidenceInterval.java:57)
	at org.apache.commons.math4.stat.interval.ClopperPearsonInterval.createInterval(ClopperPearsonInterval.java:56)
	at org.apache.commons.math4.stat.interval.IntervalUtils.getClopperPearsonInterval(IntervalUtils.java:104)
{noformat}

And:

{code}
ConfidenceInterval ci = IntervalUtils.getClopperPearsonInterval(1, 1, 0.95);
{code}

Throws:

{noformat}
Exception in thread ""main"" org.apache.commons.math4.exception.NotStrictlyPositiveException: degrees of freedom (0)
	at org.apache.commons.math4.distribution.FDistribution.<init>(FDistribution.java:85)
	at org.apache.commons.math4.distribution.FDistribution.<init>(FDistribution.java:63)
	at org.apache.commons.math4.stat.interval.ClopperPearsonInterval.createInterval(ClopperPearsonInterval.java:49)
	at org.apache.commons.math4.stat.interval.IntervalUtils.getClopperPearsonInterval(IntervalUtils.java:104)
{noformat}","03/May/17 07:40;kinow;And in R, the [PropCIs|https://artax.karlin.mff.cuni.cz/r-help/library/PropCIs/html/exactci.html] library gives:

{code}
library(PropCIs)
exactci(1, 1, 0.95)

data:  

95 percent confidence interval:
 0.025 1.000
{code}

But must admit that I'm abstracting away the fact that there are two functions for calculating clopper pearson interval (exactci and midPci). I have some links from the PropCIs R vignette (as tutorials are called in R), a [Wikipedia page I found|https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper-Pearson_interval], and another [R related web page|http://www.stat.cmu.edu/~mciollar/resources/clopper-pearson.html].

The Java code seems to be correctly checking to avoid division by zero and NaN errors. However, looking at the R implementation, it seems that we could simply add an extra case for when the denominator is zero. Though, instead of simply copying the code from other libraries, I intend to read these links before fixing the code, in order to learn what are clopper pearson intervals. If anyone beats me fixing the code, that'll be all right as well :-)","09/May/17 10:27;kinow;To make it easier, will start naming the two cases we have. Case #1 is the one I had some time to study today, and is when **number of successes is equals zero**. And Case #2 is where **number of successes is equal to the number of trials"".

The exception is raised [here|https://github.com/apache/commons-math/blob/20403f09bfe6f06626cd1253042b848e38f038fd/src/main/java/org/apache/commons/math4/stat/interval/ConfidenceInterval.java#L101]:

{code}
# class: ConfidenceInterval
    /**
     * Verifies that (lower, upper) is a valid non-empty interval and confidence
     * is strictly between 0 and 1.
     *
     * @param lower lower endpoint
     * @param upper upper endpoint
     * @param confidence confidence level
     */
    private void checkParameters(double lower, double upper, double confidence) {
        if (lower >= upper) { <---------------------- HERE, both are 0 <=> 0
            throw new MathIllegalArgumentException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper);
        }
        if (confidence <= 0 || confidence >= 1) {
            throw new MathIllegalArgumentException(LocalizedFormats.OUT_OF_BOUNDS_CONFIDENCE_LEVEL, confidence, 0, 1);
        }
}
{code}

The code is checking if the confidence interval lower and upper bounds are different. The [R code|https://artax.karlin.mff.cuni.cz/r-help/library/PropCIs/html/exactci.html] handles three cases, when the number of successes is zero, when the number of successes and trials is the same, and the case where both previous constraints are not true.

Our code in ClopperPearsonInterval checks if the number of successes is greater than 0 only. Then returns a ConfidenceInterval object.

My current guess is that by understanding why the R code is treating these three cases, we may be able to confirm if it makes sense adding some if/else for these constraints in our Java code too.

","09/May/17 10:34;kinow;Continuing on case #1, [this PDF|http://www.lexjansen.com/phuse/2013/sp/SP05.pdf] mentions that ""The lower bound is set to 0 when x = 0, and the upp
er bound is set to 1 when x = n. "". These are exact variable names in the R library, and this is exactly what is happening.

There is still the matter that the calculation is different when x >0 and x != n.","09/May/17 10:53;kinow;Found a better paper explaining it (A. Boomsma, ""Confidence Intervals for a Binomial Proportion"" link: http://www.ppsw.rug.nl/~boomsma/confbin.pdf).

{quote}
For x = 0, the lower limit r1 = 0, because the upper limit ru satisfies the equality (1 - ru) ^n = alpha / 2, from which it follows that ru = 1 - (alpha / 2) ^ 1/n.

For x = n, the upper limit ru = 1, because the lower limit satisfies r = alpha / 2, which makes r = (alpha / 2) ^ 1/n.
{quote}

Which matches exactly with the R implementation. I will update the code, and run some codes for this Case #1. In case it works, will report back here and focus on Case #2 (which could be automatically fixed by fixing Case#1 I think...).","09/May/17 11:59;kinow;Here are the results with R PropCIs:

{noformat}
data:  

95 percent confidence interval:
 0.000 0.975

> exactci(n=1, x=0, 0.95)



data:  

95 percent confidence interval:
 0.000 0.975

> exactci(n=1, x=1, 0.95)



data:  

95 percent confidence interval:
 0.025 1.000

> 
{noformat}","14/Apr/19 17:27;micdestefano;Dear all, this issue is still present.

I've found an elegant solution (from another developer) that requires very few modifications.

Look here: [ModifiedClopperPearsonInterval.java|https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=2ahUKEwigvbLVjNDhAhWOneAKHQ64CFEQFjACegQIBRAB&url=https%3A%2F%2Fgithub.com%2Fkomiya-atsushi%2Fbinomial-proportion-confidence-interval%2Fblob%2Fmaster%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fcommons%2Fmath3%2Fstat%2Finterval%2FModifiedClopperPearsonInterval.java&usg=AOvVaw18pyz4IhNzmgTo1MAH-brE]

Basically, it is sufficient to set the default for the upper bound to 1, and to perform the computation of the upper bound only when the number of successes is less than the number of trials (this is a check to be added).

I checked the correctness of the results against the same computation performed by the statsmodels Python package.","14/Apr/19 18:12;erans;bq. I've found an elegant solution 

Thanks. Patch welcome (with unit test)!

bq. (from another developer)

Please check possible license issues.
IIUC, the MIT license would require the addition of an entry in the [""NOTICE.txt"" file|https://gitbox.apache.org/repos/asf?p=commons-math.git;a=blob;f=NOTICE.txt].","15/Apr/19 06:43;micdestefano;Excuse me ... I am a user of this commons-math library, not the developer. So I think I already did more than what is required from me, because further to reporting the issue, I've also suggested its fix (which, I repeat, it's quite simple if you spend 5 minutes on it).

If, on the other hand, this library is going to be dismissed (I see that this issue is open since 2017) then please tell it clearly.

Best regards,

Michele","16/Apr/19 11:01;erans;commit 53d9c7fbfbe9cbd7e11cb872ef87e00462fa3eca","16/Apr/19 11:21;erans;bq. I am a user of this commons-math library, not the developer.

The ""developer"" is the community of users.

bq. \[...\] please tell it clearly.

The list of pending bugs is long; more than 150 issues were [fixed since the last release|https://issues.apache.org/jira/issues/?jql=project%20%3D%20MATH%20AND%20fixVersion%20%3D%204.0%20AND%20statusCategory%20%3D%20done].
","17/Apr/19 16:30;micdestefano;Dear Gilles,

I'm sorry but actually the issue is not fixed at all.

Nevertheless, I now have cloned the repo and I have a branch where I have fixed the issue and I have also provided meaningful unit tests. The only issue is that I am not able to push this branch ... I was expecting to be able to push the branch and then perform a pull request (I'm sorry but it is the first time that I try to do something like that).

Can you tell me what to do? Do you need my user name, in order to grant me the right to push my branch?","17/Apr/19 16:57;erans;bq. the issue is not fixed

What happens?

bq. I am not able to push this branch

It's expected: There is a process before being granted write access.
Mainly, it boils down to interacting with regular contributors for some time...

bq. I'm sorry but it is the first time that I try to do something like that

No problem.  Thanks a lot for continuing the effort. :-)

bq. Can you tell me what to do?

Next step would be to [subscribe to the ""dev"" mailing list|http://commons.apache.org/mail-lists.html].  It's the place where we discuss general issues.
It is certainly not necessary to have write access in order to submit a pull request.

In the meantime, you could attach a ""patch"" file to this page, so that we can further discuss this particular problem here.","17/Apr/19 21:51;micdestefano;Dear Gilles,

I've just attached the modified unit test (ClopperPearsonIntervalTest.java) and the modified (now working) code (ClopperPearsonInterval.java).

Your fix was failing to address the case with number of successes = 0.

Because I am also a data scientist and I have a lot of experience in Python scientific programming, I generated 3 meaningful test cases with expected results obtained by the same algorithm implemented in a Python package that I use (the package name is statsmodels). I use that package since a while and I trust its results (for our specific case, I've also partially verified them theoretically).

So, in the unit test you will find comments from myself, explaining which was the Python instruction I used to produce the expected numbers (so that anyone that is also able to program in Python can reproduce them).

I suspect (but I have not verified this) that we have similar issues with the implementation of the other algorithms that produce confidence intervals for the binomial distribution.

In summary, the 3 cases we need to test for each of these methods are
 # number of successes = 0, number of trials = N
 # number of successes = k, number of trials = N, 0 < k < N
 # number of successes = number of trials = N

The code I've attached now passes all the three of them.

 

Best regards,

Michele

[^ClopperPearsonIntervalTest.java]

[^ClopperPearsonInterval.java]

 ","18/Apr/19 12:58;erans;bq. I generated 3 meaningful test cases

Thanks.

{quote}
# number of successes = 0, number of trials = N
# number of successes = k, number of trials = N, 0 < k < N
# number of successes = number of trials = N
{quote}

Quite clear indeed.  And that's how the unit tests should be designed; hence [the modifications|https://gitbox.apache.org/repos/asf?p=commons-math.git;a=blob;f=src/test/java/org/apache/commons/math4/stat/interval/ClopperPearsonIntervalTest.java;h=6a06f97df656a45ba69953a94214bada271ca8f7;hb=0df313bef62d5fedc18286b80fc93248b5f180fd] to the test code which you provided.
Please have a look.

Side note: Package [{{org.apache.commons.math4.stat.interval}}|https://gitbox.apache.org/repos/asf?p=commons-math.git;a=tree;f=src/main/java/org/apache/commons/math4/stat/interval] shows its age.  A new [""Commons Statistics"" component|http://commons.apache.org/proper/commons-statistics/] is being developed as an opportunity to fix and modernize the API of the statistical utilities.  You are most welcome to help with the porting work.","18/Apr/19 15:46;micdestefano;Gilles,

I've seen the new version of the unit test and I completely agree with your modifications. The test is clearer and more effective in the form you propose (I'll keep in mind for the future ... it's actually better to encapsulate each test case in a separate method).

As soon as I can (with the limited time that I have) I will try to do a similar exercise with the other algorithms that produce confidence intervals for the binomial distribution (I can check again with Python results).

So, if you push the fixed code to the master, to me the issue is fixed.

Thanks,

Michele"
MillerUpdatingRegression: ArrayIndexOutOfBounds when calling regress with variablesToInclude parameter,MATH-1477,13227012,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,,cheesinglee,cheesinglee,09/Apr/19 17:59,10/Apr/19 01:18,20/Mar/20 20:34,10/Apr/19 01:18,3.6.1,,,,,4.0,,0,easyfix,newbie,patch,,"When performing a regression with a subset of predictors, an ArrayIndexOutOfBounds exception will occur for certain subset selections. For example, this appears to happen consistently for regressions without a constant term when the predictor at index 0 is not selected.

I do not understand at all the algorithm used to reorder the predictors when a subset is requested, but the fix appears to be a simple correction to the indexing range in the for-loop in the regress method of MillerUpdatingRegression.java.

 

Patch with expanded unit test to follow shortly.",,"cheesinglee commented on pull request #104: MATH-1477: fix reordering check in MillerUpdatingRegression.regress
URL: https://github.com/apache/commons-math/pull/104
 
 
   Test and fix for MATH-1477
 
----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/19 18:37;githubbot;600","coveralls commented on issue #104: MATH-1477: fix reordering check in MillerUpdatingRegression.regress
URL: https://github.com/apache/commons-math/pull/104#issuecomment-481394696
 
 
   
   [![Coverage Status](https://coveralls.io/builds/22703187/badge)](https://coveralls.io/builds/22703187)
   
   Coverage decreased (-0.002%) to 90.175% when pulling **55fbf2dc6e85c63fbfb8693789ec45d44f4976d5 on cheesinglee:bug-MATH-1477** into **286ab7c6dd4c4aae0b0290517ea3508487438d01 on apache:master**.
   
 
----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/19 19:06;githubbot;600","asfgit commented on pull request #104: MATH-1477: fix reordering check in MillerUpdatingRegression.regress
URL: https://github.com/apache/commons-math/pull/104
 
 
   
 
----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Apr/19 01:17;githubbot;600",,0,1800,,,0,1800,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-04-10 01:18:03.383,,,false,,,,,,,,,,Patch,,,,,,,,9223372036854775807,,,Wed Apr 10 01:18:03 UTC 2019,,,,,,,"0|z01lzk:",9223372036854775807,,,,,,,,,,,,,,,,"09/Apr/19 18:37;cheesinglee;Link to PR: [https://github.com/apache/commons-math/pull/104]","10/Apr/19 01:18;erans;PR merged (commit 8694f8478bed676c9bb13a3a9a6e2eca56029c95 in ""master"").
Thanks.",,,,,,,,,,,,,,,
IndexOutOfBoundsException when calling PolygonsSet.getSize(),MATH-1432,13098594,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Duplicate,,n,n,30/Aug/17 16:12,01/Jan/19 01:32,20/Mar/20 20:34,01/Jan/19 01:32,3.6.1,,,,,,,0,bug,exception,,,"Running the following code produces an IndexOutOfBoundsException:


    public static void main(String[] args) {
        List<Vector2D> vectors = new ArrayList<>();
        vectors.add(new Vector2D(1, 1));
        vectors.add(new Vector2D(1_189, 1));
        vectors.add(new Vector2D(1_697_165, 147));
        vectors.add(new Vector2D(1_592_444, 249_323));
        vectors.add(new Vector2D(248_665, 110_887));
        vectors.add(new Vector2D(37_142, 24_654));
        vectors.add(new Vector2D(10_093, 8_137));
        vectors.add(new Vector2D(966, 823));
        vectors.add(new Vector2D(25, 25));
        new MonotoneChain().generate(vectors).createRegion().getSize();
    }

Forgive the weird vector values!","Linux Fedora
Java 8",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-01-10 14:22:40.435,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 01 01:32:39 UTC 2019,,,,,,,"0|i3jghz:",9223372036854775807,,,,,,,,,,,,,,,,"10/Jan/18 14:22;nkollar;This is fixed on master (see MATH-1436), and will be included in 4.0. It looks like no new release is planned on 3.6.x branch, I guess you'll have to upgrade to 4.0.","10/Jan/18 14:56;erans;bq. It looks like no new release is planned on 3.6.x branch, I guess you'll have to upgrade to 4.0.

There are/have been discussions on the ""dev"" ML towards moving the contents of package {{org.apache.commons.math4.geometry}} into its own component (i.e. ""Commons Geometry"").
Let us know if you'd be willing to help with the move (e.g. be a ""beta-tester"").
","10/Jan/18 16:28;nkollar;[~erans] what kind of help do you require from a ""beta-tester""? I'm not directly using commons math, but if I can fit it into my time, I'm happy to help.","10/Jan/18 17:18;erans;bq. kind of help

After creating a repository, the first thing would be to move (and adapt) the code and unit tests.
See e.g. what is being done in [""Commons Numbers""|https://git-wip-us.apache.org/repos/asf?p=commons-numbers.git] (also split of ""Commons Math"").
Reviewing the API would also be nice.
If not done already, please subscribe to the ""dev"" ML; it will be necessary to coordinate who does what.
Thanks!
","01/Jan/19 01:32;erans;The OP marked this issue as duplicating a resolved one.",,,,,,,,,,,,
BicubicInterpolatingFunction not interpolating correctly for non discrete y value,MATH-1471,13191002,Bug,Closed,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Invalid,,tswinicki,tswinicki,11/Oct/18 17:36,18/Oct/18 16:22,20/Mar/20 20:34,18/Oct/18 16:22,3.6.1,,,,,,,0,,,,,"Upon performing a bicubic interpolation with two point (x0, y0) and (x1, y1), the returned bicubic interpolating function returned returns the same result for variations in the estimated y value. 

For example, my inputs are (20, 20) and (25, 25) with f(20, 20) = 64 and f(25, 25) = 6468.

When I get the bicubic interpolating function for this and vary the estimated x, it works fine. For (21, 20), the function returns 730.016. When I input (20, 21), the function returns 64, which is f(20, 20). For any y value in between 20 and 25, the result is 64. This is the case for any function for which the y estimate is different from the value on the points. 

In other instances, it is varying x values that result in the same result while varying y estimates seem to work as expected.",JDK 1.8.0_181 ,,,,,,,,,,,,,,,,"12/Oct/18 14:17;tswinicki;ApacheCommonsMathBiInterpolationTests.zip;https://issues.apache.org/jira/secure/attachment/12943651/ApacheCommonsMathBiInterpolationTests.zip","15/Oct/18 13:12;tswinicki;Interpolate.java;https://issues.apache.org/jira/secure/attachment/12943938/Interpolate.java","15/Oct/18 13:12;tswinicki;InterpolateTest.java;https://issues.apache.org/jira/secure/attachment/12943939/InterpolateTest.java",,3.0,,,,,,,,,,,,,,,,,,,,2018-10-11 18:23:08.325,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 15 13:35:46 UTC 2018,,,,,,,"0|i3z3jr:",9223372036854775807,,,,,,,,,,,,,,,,"11/Oct/18 18:23;erans;bq. interpolating function returned returns the same result for variations in the estimated y value.

Thanks a lot for the report.
Could you please set up a unit test that demonstrates the bug, in the form of a patch (or ""pull request"") against the development version (i.e. the code in the ""master"" branch of the repository)?
A fix would also be welcome. :)","12/Oct/18 14:44;tswinicki;The pull request has been made and I have also attached the unit tests to this issue. Thanks for the prompt reply!","12/Oct/18 23:35;erans;{quote}I have also attached the unit tests to this issue.
{quote}
What you have attached is an archive of your copy of the repository, plus your compiled files and the generated web site. :(
 Please upload a patch file.
{quote}The pull request has been made
{quote}
Where is it (I didn't get any notification)?
 Alternatively to the patch file, please copy here the link to the pull request. Thanks.","15/Oct/18 13:12;tswinicki;Sorry, the Apache Commons Math Library is included in the zip file, but under the src folder there is a class called Interpolate.java which implements the BicubicInterpolator in a method. Under tests folder, there is an InterpolateTest.java which contains a unit test for the BicubicInterpolatingFunction. I have uploaded just the java files as well for easier access,

 

Here is the pull request link! https://github.com/apache/commons-math/pull/90","15/Oct/18 13:35;erans;Hi Tom.

It's great that you want to contribute to the project but please read [how to do it|http://commons.apache.org/proper/commons-math/developers.html] (see especially the paragraph on using ""git"") in order to make it easy for us to apply the necessary changes.
 I don't know the steps for generating a PR on Github but if you post on the [""dev"" mailing list|http://commons.apache.org/proper/commons-math/mail-lists.html] asking for help, I hope that someone can explain them.
{quote}Here is the pull request link!
{quote}
Sorry but it is just a link to a ZIP file (same as you attached here, I guess) whereas it should only contain a ""diff"" wrt the ""master"" branch. In particular, the provided unit test should be a patch to apply to the [existing test suite for the class being tested|https://git1-us-west.apache.org/repos/asf?p=commons-math.git;a=blob;f=src/test/java/org/apache/commons/math4/analysis/interpolation/BicubicInterpolatorTest.java;h=bf3195c2a896ad4969b9b9cfa88687a1010fdfe0;hb=HEAD].",,,,,,,,,,,,
Precision.round(double...)'s use of Double.toString(x) rounds twice resulting in inaccuracy,MATH-1470,13188979,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,litesoft,litesoft,02/Oct/18 21:17,03/Oct/18 14:46,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"The use of Double.toString( x ) in the creation of the BigDecimal used by the Precision.round(double...) methods introduces a rounding that can then generate incorrect results when the rounding is applied to the BigDecimal.  Whenever possible rounding should only be applied to the most accurate value available.  Switching the BigDecimal construction to use the double value directly resolves the problem.

 

This problem can be seen by running the main method of the com.altoros.floatingpoint.PrecisionProblem class in the repo hosted at: [https://github.com/Altoros/precision-problem]

 

George

 ",,,,,600,600,,0%,600,600,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-10-03 14:46:34.862,,,false,,,,,,,,https://github.com/Altoros/precision-problem,,,,,,,,,,9223372036854775807,,,Wed Oct 03 14:46:34 UTC 2018,,,,,,,"0|i3yr5z:",9223372036854775807,,,,,,,,,,,,,,,,"03/Oct/18 14:46;erans;Hi.

Thanks for the report and analysis.
Class {{Precision}} has been [moved to the ""Commons Numbers"" project|https://git1-us-west.apache.org/repos/asf?p=commons-numbers.git;a=blob;f=commons-numbers-core/src/main/java/org/apache/commons/numbers/core/Precision.java;h=11fe704383e46ee421a1c0c344dd86d86a2bcdbc;hb=HEAD], and so won't be part of the next major release (v4.0) of ""Commons Math"".
Could you please file an issue in the [bug tracking system for ""Numbers""|https://issues.apache.org/jira/projects/NUMBERS/issues/], linking that issue to this one?  Thanks.

It would of course be great if you could also provide a fix in the form of patch (or pull request) containing the necessary code changes and associated unit test(s).
",,,,,,,,,,,,,,,,
CMAES Optimization Fails to find Actual Optimum if Solution Value is Negative,MATH-1466,13181429,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,rwolkoff,rwolkoff,27/Aug/18 18:19,29/Aug/18 00:26,20/Mar/20 20:34,,3.6.1,,,,,,,0,Optimization,,,,"Class CMAESOptimizer ([java.lang.Object|http://docs.oracle.com/javase/6/docs/api/java/lang/Object.html?is-external=true]

[org.apache.commons.math3.optim.BaseOptimizer|http://commons.apache.org/proper/commons-math/javadocs/api-3.4/org/apache/commons/math3/optim/BaseOptimizer.html]<PAIR>

[org.apache.commons.math3.optim.BaseMultivariateOptimizer|http://commons.apache.org/proper/commons-math/javadocs/api-3.4/org/apache/commons/math3/optim/BaseMultivariateOptimizer.html]<[PointValuePair|http://commons.apache.org/proper/commons-math/javadocs/api-3.4/org/apache/commons/math3/optim/PointValuePair.html]>

[org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer|http://commons.apache.org/proper/commons-math/javadocs/api-3.4/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateOptimizer.html]

org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer)

I cannot provide code as I work for a private company with IP. However, my tests indicate that if the we are minimizing a cost function, and the function's value is a negative value, the resulting solution is incorrect.

For example, say I were minimizing y = x^2 - 100

The solution should be x = 0, with a value of -100. However, this CMAES optimizer would find random solutions, like x = 3 or x = -2 (with solutions of -91 and -96 respectively).

I used the BOBYQA solver, and it was able to find the solution of x = 0 with a value of y = -100. I tested y = x^2 + 100 and the CMAES solver was able to find a solution of x = 0, y = 100. I tested y = x^2 and the CMAES the CMAES solver was able to find a solution of x = 0, y = 0. I tested y = x^2 -1 and the CMAES solver was NOT able to find a solution of x = 0, y = -1.

I know it is highly inconvenient, but if someone wants to take a look at my cost function I can try to get an NDA. I think this bug is reproducible without it. Feel free to contact me at [rwolkoff@umich.edu|mailto:rwolkoff@umich.edu] if more info is needed.

I think it has to do with the following stop criteria, which ends early if the cost is negative:

if (stopFitness != 0 && bestFitness < (isMinimize ? stopFitness : -stopFitness)) {
 break generationLoop;
}

 ",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-08-29 00:26:48.393,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Aug 29 00:26:48 UTC 2018,,,,,,,"0|i3xgyn:",9223372036854775807,,,,,,,,,,,,,,,,"29/Aug/18 00:26;erans;bq. I think it has to do with the following stop criteria, which ends early if the cost is negative

It is spot on, indeed.
But this condition is controlled by the {{stopFitness}} argument to the [constructor|http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math4/optim/nonlinear/scalar/noderiv/CMAESOptimizer.html#CMAESOptimizer-int-double-boolean-int-int-org.apache.commons.rng.UniformRandomProvider-boolean-org.apache.commons.math4.optim.ConvergenceChecker-].  Which value do you use?
I've added a [unit test|https://git1-us-west.apache.org/repos/asf?p=commons-math.git;a=commit;h=efb0230063b31d53bd077d9f6a4bb64fcbb9c97f] for {noformat}f(x) = x^2 - 100{noformat} that shows that the implementation should also work if the optimum has a negative fitness.
",,,,,,,,,,,,,,,,
EmpiricalDistribution cumulativeProbability can return NaN when evaluated within an empty bin.,MATH-1431,13098387,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,jlin61,jlin61,29/Aug/17 20:51,11/Jun/18 13:04,20/Mar/20 20:34,,3.6.1,,,,,,,1,,,,,"The NaN can be reproduced by the following program. Evaluating at x = 0.3, it appeared that getkernel returned a NormalDistribution with mean of NaN and standardDeviation of NaN.

{code:java}
    final int len = 240000;
    double[] data = new double[len];
    for (int i = 0; i < len / 2; ++i) {
        data[i] = 0;
    }
    for (int i = len / 2 + 1; i < len ; ++i) {
        data[i] = 1;
    }

    int binCnt = Math.max(1, data.length / 10);
    EmpiricalDistribution edist = new EmpiricalDistribution(binCnt);
    edist.load(data);
    double x = 0.3;
    double y = edist.cumulativeProbability(x);
    System.out.println(""y is "" + y);
{code}",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-10-15 20:54:01.213,,,false,,,,,,,,,,Important,,,,,,,,9223372036854775807,,,Sun Oct 15 20:54:01 UTC 2017,,,,,,,"0|i3jf7z:",9223372036854775807,,,,,,,,,,,,,,,,"15/Oct/17 20:54;psteitz;The diagnosis above is correct.  The error is in EmpiricalDistribution#getKernel, which checks for singleton or no-variance bins, but not empty bins.  The fix is to change the test in getKernel to also return constant distribution for empty bins.  This is fixed in Hipparchus here: https://github.com/Hipparchus-Math/hipparchus/commit/96fdfa07b56f51cd4c398f6e659a064f43a4178f
",,,,,,,,,,,,,,,,
Infinite loop for CycleCrossover with duplicates,MATH-1451,13138344,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,elastxy,elastxy,13/Feb/18 21:41,15/Feb/18 09:38,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"I've found an infinite loop when recombining two integers Chromosomes admitting duplicates with CycleCrossover class.

For example, recombining example Chromosomes it works fine, but, if you substitute all ""8"" with ""7"", you run into an infinite loop while mating.

I attach the self-contained unit test (JUnit) for a better comprehension (issue a mvn clean install to run).

I added a little quick patch to fix, which I'm happy to provide, even could be less efficient than original.",Home PC,,,,,,,,,,,,,,,,"13/Feb/18 21:40;elastxy;test-apache-math3.zip;https://issues.apache.org/jira/secure/attachment/12910452/test-apache-math3.zip",,,,1.0,,,,,,,,,,,,,,,,,,,,2018-02-13 22:20:49.045,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 15 09:38:21 UTC 2018,,,,,,,"0|i3q5jz:",9223372036854775807,,,,,,,,,,,,,,,,"13/Feb/18 22:20;erans;Hello Gabriele.
Thanks for the report.
However, as you might have seen from recent activity on JIRA, or the ""Commons"" project ""dev"" ML, the monolithic ""Commons Math"" library is being phased out in favour of smaller, more focused, modular components:
* [Commons RNG|http://commons.apache.org/rng]
* [Commons Numbers|http://commons.apache.org/numbers]
* [Commons Statistics|http://commons.apache.org/proper/commons-statistics/]
* ...

Moreover, although being the last official release, v3.6.1 is obsolete because of the evolutions (bug fixes and refactoring) that happened on the ""master"" branch (geared towards v4.0) during the last 3 years.

This is to say that if you are a heavy user of the {{genetics}} package, and are able, and willing, to maintain it, you are welcome to signal it on the ""dev"" ML. The ensuing discussion would clarify whether a new ""Commons Genetics"" component would be acceptable to the project leaders.","14/Feb/18 20:01;elastxy;Hi Gilles, thank you for clarification, sounds good. Sent an e-mail to ""dev"" ML.","15/Feb/18 09:38;erans;bq.  Sent an e-mail to ""dev"" ML.

I haven't seen any post.  Did you subscribe first?",,,,,,,,,,,,,,
PolygonsSet Infinite Lines and SubOrientedPoint Tolerance Issues,MATH-1436,13126131,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,,mattjuntunen,mattjuntunen,20/Dec/17 03:26,10/Jan/18 14:23,20/Mar/20 20:34,25/Dec/17 09:52,3.5,3.6,3.6.1,4.0,,4.0,,0,,,,,"These are two separate issues that I found while using the partitioning code from 3.5 to work with complex solid models. The issues are:
1. org.apache.commons.math[34].geometry.euclidean.oned.SubOrientedPoint uses a hardcoded tolerance of 1.0e-10 instead of the tolerance from the parent hyperplane. This causes issues when working with a tolerance other than the default.
2. org.apache.commons.math[34].geometry.euclidean.twod.PolygonsSet fails on infinite line segments. An IndexOutOfBoundsException is thrown when a PolygonsSet is created with a single infinite SubLine as a boundary and a NullPointerException is thrown when one is created with a mix of finite and finite boundaries.
I will be attaching a pull request shortly with fixes and unit tests.

UPDATE:
-Pull request for v4.0: [https://github.com/apache/commons-math/pull/70]-
-Pull request for v3.6.x: [https://github.com/apache/commons-math/pull/71]- (removed; no future releases planned for v3.x)

UPDATE [2017-12-23]:
Split initial pull request into two separate ones:
- SubOrientedPoint changes: [https://github.com/apache/commons-math/pull/72]
- PolygonsSet changes: [https://github.com/apache/commons-math/pull/73 ]",,,,,,,,,,,,,,MATH-1432,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-12-21 15:15:43.926,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 25 09:52:20 UTC 2017,,,,,,,"0|i3o3sn:",9223372036854775807,,,,,,,,,,,,,,,,"21/Dec/17 15:15;erans;Hello.

Thank you for the report and fixes.

bq. These are two separate issues

Would you mind making two separate patches to help tracking of the changes? Thanks.
Also, as I'm not knowledgeable in this part of the codebase, could you perhaps write a more elaborate comment to describe the new statements (e.g. around line 850 in ""PolygonsSet.java"").

bq. Pull request for v3.6.x

No release based on the 3.x branch is planned anymore.
A few weeks ago, there was a discussion (on the ""dev"" ML, see [archive|http://markmail.org/message/75vuyhzblfadc5op]) to move the contents of package {{org.apache.commons.math4.geometry}} into a component of its own (i.e. ""Commons Geometry"") as part of a major overhaul towards modularizing ""Commons Math"" which, in the current circumstances, is not maintainable as a monolithic library.
Work is underway: components [""Commons RNG""|https://commons.apache.org/rng] and [""Commons Numbers""|https://commons.apache.org/numbers] have already been created.
As a user, your input is important; and you are most welcome to help getting there.","22/Dec/17 03:26;mattjuntunen;Hi. Thanks for the feedback. When you say to create two separate patches, do you mean to close this issue and create two new ones with separate pull requests or just to create two pull requests for this one issue?

That's good to know about the 3.x branch. I'll remove that pull request.

Reading the mailing list thread you posted was quite informative. That gave me a much better picture for the current state of the project. I'm using the geometry code from v3.6.1 quite a bit in my current project and I keep running up against issues and things I'd like to update (specifically in the partitioning package). So, I'd be very interested in helping out if this code is going to be refactored at all.","22/Dec/17 11:03;erans;bq. do you mean to close this issue and create two new ones with separate pull requests

For future work, one report per issue is the best option.

bq. just to create two pull requests for this one issue

That'll be fine but please make the log message (for each issue) a little more explicit than ""adding fixes"". ;)

bq. I'm using the geometry code from v3.6.1 quite a bit in my current project \[...\] So, I'd be very interested in helping out

Currently, you're probably the one with the most expertise with this part of the library; thanks a lot for the offer.","23/Dec/17 19:28;mattjuntunen;I split the pull request in two and added the new links in the issue description. There's also a few more unit tests and more comments. And better commit messages, too :-)

Let me know if this will work or not. Thanks.","25/Dec/17 09:52;erans;Merged in ""master"" (with tabs removed).",,,,,,,,,,,,
"""NaturalRankingTest"" broken?",MATH-1361,12969776,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,erans,erans,14/May/16 17:23,23/Oct/17 18:13,20/Mar/20 20:34,,3.6.1,,,,,4.0,,0,test,,,,"As reported on the [""dev"" ML|http://markmail.org/message/2oqkvx33arjj34lz], the test method
{noformat}
testNaNsFixedTiesRandom()
{noformat}
reports failure for more than 96 out of 100 seed values.
",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-10-23 18:13:46.275,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 23 18:13:46 UTC 2017,,,,,,,"0|i2xz6v:",9223372036854775807,,,,,,,,,,,,,,,,"23/Oct/17 18:13;psteitz;This is the result of sloppy test implementation (by me).  The TiesRandom strategy assigns ranks randomly among the applicable ranks, so the expected values are in fact stochastic.  To eliminate seed dependency, the expected values for ties need to be allowed to vary over the possible ranks.  One way to do that is the fix that I applied to Hipparchus for this issue [https://github.com/Hipparchus-Math/hipparchus/commit/9cc199a7c7b2051a02bd1db060caf43a00748f2b].",,,,,,,,,,,,,,,,
Wrong eigen values computed by EigenDecomposition when the input matrix has large values,MATH-1424,13085127,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,Jerome834,Jerome834,06/Jul/17 08:07,06/Jul/17 11:13,20/Mar/20 20:34,,3.6.1,,,,,,,0,easyfix,,,,"The following code gives a wrong result:
RealMatrix m = [[10_000_000.0, -1_000_000.0],[-1_000_000.1, 20_000_000.0]]; // pseudo code
EigenDecomposition ed = new EigenDecomposition(m);
double[] eigenValues = ed.getRealEigenvalues();

Computed values: [1.57E13, 1.57E13].
Expected values: [1.0E7, 2.0E7]

The problem lies in method EigenDecomposition.transformToSchur(RealMatrix).
At line 758, the value matT[i+1][i] is checked against 0.0 within an EPSILON margin.
If the precision of the computation were perfect, matT[i+1][i] == 0.0 means that matT[i][i] is a solution of the characteristic polynomial of m. In the other case there are 2 complex solutions.
But due to imprecisions, this value can be different from 0.0 while m has only real solutions.
The else part assume that the solutions are complex, which is wrong in the provided example.
To correct it, you should resolve the 2 degree polynomial without assuming the solutions are complex (that is: test whether p*p + matT[i+1][i] * matT[i][i+1] is negative for 2 complex solutions, or positive or null for 2 real solutions).
You should also avoid testing values against something within epsilon margin, because this method is almost always wrong in some cases. At least, check with a margin that depends on the amplitude of the value (ex: margin = highest absolute value of the matrix * EPSILON); this is still wrong but problems will occur less often.

The problem occurs when the input matrix has large values because matT has values of magnitude E7. MatT[1, 0] is really low (E-10) and you can not expect a better precision due to the large values on the diagonal.
The test within EPSILON margin fails, which does not occurs when the input matrix has lowest values.
Testing the code with m2 = m / pow(2, 20) will work, because matT[1, 0] is now low enough.",JDK 7.51 64 bits on Windows 7.,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-07-06 10:33:34.869,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jul 06 11:13:18 UTC 2017,,,,,,,"0|i3h6hb:",9223372036854775807,,,,,,,,,,,,,,,,"06/Jul/17 10:33;erans;Thanks for the report.
Could you prepare a patch, with unit test, against the current development version (""master"" branch of the repository)?
","06/Jul/17 11:04;Jerome834;Yes, but not before September (too much workload now).","06/Jul/17 11:13;erans;Fine, since it's unlikely that we'll be in a position to consider a release of ""Commons Math"" before we finalize the initial release of [""Commons Numbers""|http://commons.apache.org/proper/commons-numbers/modules.html].",,,,,,,,,,,,,,
WilsonConfidenceInterval returning negative values,MATH-1421,13081335,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,,mathijs,mathijs,21/Jun/17 07:29,22/Jun/17 01:21,20/Mar/20 20:34,22/Jun/17 01:21,3.6.1,,,,,4.0,,0,,,,,"Wilson confidence intervals sometimes return negative values as the lower bound, e.g.
IntervalUtils.getWilsonScoreInterval(19436, 0, 0.95).getLowerBound() returns -1.3549849074815073E-20

This is causing assertion fails in our code, which we have fixed it now by wrapping the confidence score bounds in Math.max(0, Math.min(1, bound)) until the method doesn't return wrong results anymore.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-06-22 01:21:33.607,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jun 22 01:21:33 UTC 2017,,,,,,,"0|i3gj5b:",9223372036854775807,,,,,,,,,,,,,,,,"22/Jun/17 01:21;erans;Thanks for the report.

As of commit 612a04d6b0ff8fa3060d5e943f4f72968ea71700 the reported failure does not happen anymore.
Please have a look, and reopen this issue if you have other case that still produce a negative value.
",,,,,,,,,,,,,,,,
weird result in RRQR decomposition.,MATH-1417,13070345,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,lecomtje,lecomtje,09/May/17 08:56,10/May/17 09:54,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"When using RRQRDecomposition on rank deficient matrix, results are wrong.

double[][] Xi = {
            {0, 0, 0, 0, 0, 0, 0, 0, 0},
            {0, 1, 0, 0, 0, 0, 0, 0, 0},
            {0, 0, 1, 0, 0, 0, 0, 0, 0},
            {0, 0, 1, 0, 0, 0, 0, 0, 0},
            {0, 0, 1, 0, 0, 0, 0, 0, 0},
            {0, 0, 0, 1, 0, 0, 0, 0, 0},
            {0, 0, 0, 0, 0, 0, 1, 0, 0},
            {0, 0, 0, 0, 0, 0, 0, 0, 0},};

With this matrix, i obtain: 

rank 6

R:
|1,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 1,000 1,000 1,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 1,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 1,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|

Q:
|0,000 0,000 1,000 0,000 0,000 0,000 0,000 0,000 0,000|
|1,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 1,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 1,000 0,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 1,000 0,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 1,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 1,000 0,000 0,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 1,000 0,000|
|0,000 0,000 0,000 0,000 0,000 0,000 0,000 0,000 1,000|

Where Scipy (lapack) or ejml gives me:
rank 4
Type = dense real , numRows = 9 , numCols = 8
-1,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000  -1,000   0,000   0,000  -1,000   0,000  -1,000   0,000  
 0,000   0,000  -1,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000  -1,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  

Type = dense real , numRows = 9 , numCols = 9
 0,000   0,000   0,000   0,000   0,000   0,000   1,000   0,000   0,000  
-1,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000  -1,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000  -1,000   0,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   1,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   1,000   0,000   0,000   0,000  
 0,000   0,000   0,000  -1,000   0,000   0,000   0,000   0,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   1,000   0,000  
 0,000   0,000   0,000   0,000   0,000   0,000   0,000   0,000   1,000  

That are the results i expect.



 ","linux RH6
netbeans 8.2 
java 1.8",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-05-09 10:52:01.626,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 10 09:54:35 UTC 2017,,,,,,,"0|i3ep1j:",9223372036854775807,,,,,,,,,,,,,,,,"09/May/17 10:52;erans;Thanks for the report!

Are you willing to dig into the code in order to locate the bug?","09/May/17 12:00;lecomtje;Hi Gilles,

Why not ? 
Is common math easily compiled once i checked it out  from git ?

Thanks.

Jef

","09/May/17 12:06;erans;bq. Is common math easily compiled once i checked it out from git ?

Asumimg that you have ""maven"" installed, it should just be a matter of running this command:
{noformat}
mvn compile
{noformat}
","09/May/17 14:15;lecomtje;Ok, i got the source.
I'm not a QR specialist. I took a look at the code and I've found what gave me that weird result.

In performHouseholderReflection:(RRQRDecomposition.java:111), just change
for (int j = 0; j < qrt[i].length; j++) {
(Norm is computed against the whole column )
By
for (int j = minor; j < qrt[i].length; j++) {
(Norm is computed under the current pivot )

 In performHouseholderReflection:(QRDecomposition.java:139-143) the norm is calculated again using  the column starting from minor pivot, 
then in my case, I have a column whose values are before the diagonal ( then before the pivot ). This gives a ""full norm"" that is not null but that is null beside pivot.
This column is given for computing a reflector but this calculous failed ( a == 0) because ""restricted norm"" is null.

If norms are computed always the same manner, the pivoting is ok and the result is ok in my test case.

Further testing should be done but maybe it can be a quick fix.

Hope this can help.

I'm also surprised to see a test (a!=0) in QR Decomposition with double values.
","09/May/17 14:41;erans;Have you checked out the git ""master"" branch?
With your example (and no change to the source), I obtain 4 as the rank value.","09/May/17 15:56;lecomtje;Sorry, but i am searching a nullspace and so i work with Xi transposed, not Xi by itself. And with this transposed matrix I should also obtain rank 4.
I didn't test master branch but the code seems the same.
","09/May/17 19:35;erans;Got it. :)
Please check that commit ed1ce82d822ffe185875b7b7d38352f20171c096 fixed the problem.
","10/May/17 09:32;lecomtje;Ok, it's ok for me.

I use the current stable release 3.6.1 of apache math in an industrial product.
How should I proceed to take advantage of this fix ?
","10/May/17 09:54;erans;Side-note: When you add a comment, please disable quoting of previous comments.

bq. How should I proceed to take advantage of this fix ?

It depends on your requirements.
Best is to start a thread on the ""dev"" ML.",,,,,,,,
OLS/GLS Regression sufficient data test is overly aggressive when there is no intercept term,MATH-1392,13020308,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,psteitz,psteitz,12/Nov/16 22:05,12/Apr/17 00:01,20/Mar/20 20:34,,3.6,3.6.1,,,,4.0,,0,,,,,"See https://github.com/Hipparchus-Math/hipparchus/issues/13
for full description and patch.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2016-11-12 22:05:08.0,,,,,,,"0|i3699b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LoessInterpolator can update bandwidth interval incorrectly,MATH-1379,12983827,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,rwaj,rwaj,27/Jun/16 15:43,11/Apr/17 23:59,20/Mar/20 20:34,,3.6.1,,,,,4.0,,0,,,,,"LoessInterpolator.updateBandwidthInterval assumes that the bandwidth interval cannot step by more than one index value for each call. This may not be true if the xvals are unevenly spaced (or are so after points with zero weight are omitted).

Patch available with additional tests.",,,,,,,,,,,,,,,,,"30/Jun/16 13:22;rwaj;MATH-1379-loess-interval-update.patch;https://issues.apache.org/jira/secure/attachment/12815455/MATH-1379-loess-interval-update.patch",,,,1.0,,,,,,,,,,,,,,,,,,,,2016-06-28 10:43:35.936,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 28 14:57:09 UTC 2016,,,,,,,"0|i306z3:",9223372036854775807,,,,,,,,,,,,,,,,"28/Jun/16 10:43;erans;Thanks for the report.

bq. Patch available with additional tests.

Please attach them to this page.
","28/Jun/16 11:18;erans;Could you make this patch against the development version?
It is in branch ""develop"" of the git repository.
Thanks.
","28/Jun/16 12:44;erans;Thanks for the update.
Sorry I hadn't looked further, but I find it confusing that the patch refers to MATH-296 (in comments and method names), rather than this report.
It's fine to use the same test case but the issue being different, a code reviewer should be directed to here.
","28/Jun/16 14:33;rwaj;Is there a convention for or against using issue ids in test method names?","28/Jun/16 14:57;erans;It is fine to use an issue id, but the id should be the proper one: this report is MATH-1379 so a related test method would be {{testMath1379}}, not {{testMath296}}.

Note however that test methods are better named according to what they are supposed to check, without necessarily referring to a JIRA report.
The latter is used as a last resort.

For example, this gives full information (what is checked, and that the unit resulted from a JIRA report):
{code}
    // Cf. MATH-1379
    @Test
    public void testUpdateBandwidthIntervalWithUnevenXSpacing() {
      // ...
    }
{code}
",,,,,,,,,,,,
Collinearity test: QR Decomposition rank incorrect (SVD ok),MATH-1403,13045702,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,,,hmf,hmf,23/Feb/17 18:24,10/Apr/17 14:45,20/Mar/20 20:34,,3.6.1,,,,,4.0,,0,,,,,"Hello,

I am aware that such a question have been asked before but I cannot seem to solve this issue for a very simple example. The closest example I have is:

https://issues.apache.org/jira/browse/MATH-1100

from which I could not get an answer.

I am trying to copy an algorithm from R's Caret package that identifies collinear columns of a matrix [1]. I am assuming a ""long"" matrix and and am using the trivial example from the reference above. However I cannot get this to work because the QR's rank result is incorrect.

I have the following example:

import org.apache.commons.math3.linear.RealMatrix;
import org.apache.commons.math3.linear.RRQRDecomposition;
import org.apache.commons.math3.linear.Array2DRowRealMatrix;
import org.apache.commons.math3.linear.SingularValueDecomposition ;

public class QRIssue {

  public static void main(String[] args) {

    double[][] am = new double[5][];
    double[] c1 = new double[] {1.0, 1.0, 1.0, 1.0, 1.0, 1.0} ;
    double[] c2 = new double[] {1.0, 1.0, 1.0, 0.0, 0.0, 0.0} ;
    double[] c3 = new double[] {0.0, 0.0, 0.0, 1.0, 1.0, 1.0} ;
    double[] c4 = new double[] {1.0, 0.0, 0.0, 1.0, 0.0, 0.0 } ;
    double[] c6 = new double[] {0.0, 0.0, 1.0, 0.0, 0.0, 1.0 } ;

    am[0] = c1 ;
    am[1] = c2 ;
    am[2] = c3 ;
    am[3] = c4 ;
    am[4] = c6 ;

    Double threshold = 1e-1;

    Array2DRowRealMatrix m = new Array2DRowRealMatrix( am, false )  ; // use array, don't copy
    RRQRDecomposition qr = new RRQRDecomposition( m,  threshold) ;
    RealMatrix r = qr.getR() ;
    int numColumns = r.getColumnDimension() ;
    int rank = qr.getRank( threshold ) ;
    System.out.println(""QR rank: "" + rank) ;
    System.out.println(""QR is singular: "" + !qr.getSolver().isNonSingular()) ;
    System.out.println(""QR is singular: "" + (numColumns == rank) ) ;

    SingularValueDecomposition sv2 = new org.apache.commons.math3.linear.SingularValueDecomposition(m);
    System.out.println(""SVD rank: "" + sv2.getRank()) ;
    }
}


For SVD I get a rank of 4 which is correct (columns 0,1,2 are collinear : c0 = c1 + c2). But for QR I get 5. I have tried several thresholds with no success. For several subsets of the columns above (example only 0,1,2 I get the correct answer). What am I doing wrong?

TIA,
Hugo F.


1. https://topepo.github.io/caret/pre-processing.html#lindep

","Linux ubuntu
JDK 8",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-02-24 13:41:08.506,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 27 14:23:59 UTC 2017,,,,,,,"0|i3aixj:",9223372036854775807,,,,,,,,,,,,,,,,"24/Feb/17 13:41;erans;It looks wrong indeed.
The Javadoc mentions ""When a large fall in norm is seen, the rank is returned"" which seems fairly unhelpful in order to select an appropriate threshold value.

As human resources have become scarce for the Commons Math project, you are most welcome to look at the code in order to find the bug.
I've slightly modified your example (transformed into a unit test):
{code}
    @Test
    public void testMath1403() {
        final double delta = 1e-7; // Test fails when delta <= 1e-8.
        final double[][] m = {
            {1, 1, 1, 1 + delta, 1, 1},
            {1, 1, 1, delta, 0, 0},
            {0, 0, 0, 1, 1, 1},
            {1, 0, 0, 1, 0, 0},
            {0, 0, 1, 0, 0, 1}
        };

        final RRQRDecomposition qr = new RRQRDecomposition(new Array2DRowRealMatrix(m));
        final double dropThreshold = 1e-7; // Test fails when dropThreshold <= 1e-8.
        Assert.assertEquals(4, qr.getRank(dropThreshold));
    }
{code}
It hints at a numerical problem...
","27/Feb/17 11:50;hmf;Hello Gilles,

Thanks for the feedback. Unfortunately I am not knowledgeable enough to tackle this task.

Finally, I confirmed that the original R code uses the BLAS library. Its implementation
is also a rank revealing QR decomposition. What I find interesting is that the rank value
is obtained after the decomposition and no explicit function is called. So these 
don't seem to be implementations of the same algorithm. 

As I said, I don't know much about numerical methods. However, if someone can
point me to a simple description of an algorithm I could try and debug it. 

Thanks","27/Feb/17 14:15;erans;bq. Unfortunately I am not knowledgeable enough to tackle this task.

It could start by finding out a reference algorithm (either in a scientific textbook or paper) or another code that implements the functionality, and figure out where the key differences are).
Unfortunately the Javadoc is out-of-sync since it refers to Jama having this same algo, whereas it [hasn't|http://math.nist.gov/javanumerics/jama/doc/].
","27/Feb/17 14:23;erans;Jama's documentation for says:
{noformat}
public int rank()

    Matrix rank

    Returns:
        effective numerical rank, obtained from SVD.
{noformat}
",,,,,,,,,,,,,
Kolmogorov-Smirnov fixTies can set minDelta too small for jiggler to have significant effect,MATH-1405,13047102,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,,dfinkel,dfinkel,28/Feb/17 21:38,19/Mar/17 17:53,20/Mar/20 20:34,19/Mar/17 17:53,3.6.1,,,,,,,0,,,,,"For samples that do not exceed LARGE_SAMPLE_PRODUCT with their product and relatively large values, a minDelta can be calculated in fixTies() that is too small to have any effect on the ""tied"" values. This results in a MathInternalError, as the jiggling with the ineffective minDelta fails to fix the ties.

The following arrays exhibit this behavior when run with kolmogorovSmirnovTest(x, y) in 3.6.1

x = [1.3750969645841487, 1.0845460746754014, 1.3693352427126644, 1.329688765445783, 1.3392109491039106, 1.3532766470312723, 1.3187287426697727, 1.386273031970554, 1.3416950149276097, 1.0510872606482404, 1.3532766470312723, 1.3075923871137798, 1.3862730319705543, 1.3814421433922548, 1.0527927570919202, 1.3847314864464313, 1.319362658529506, 1.3579238253227275, 1.2455452272301641, 1.329688765445783, 1.3827781646781876, 1.0755168081687903, 1.2566273460024566, 1.3099622795250825, 1.357440924560318, 1.3519397370266515, 1.0927347979524134, 1.3566357346921618, 1.238800036669969, 1.2931730628634528, 1.048463407884969, 1.3779471642491719, 1.2978533797116658, 1.376230881554943, 1.166901202345226, 1.3690425182006263, 1.166901202345226, 1.2953476417603207, 1.0827945761165951, 1.2942406680885112, 1.224414840377028, 1.3910905417259205, 1.303231085263425, 1.348635183816037, 1.3750969645841487, 1.049648651501274, 1.3119534979602083, 1.0446033225080773, 1.0494686631294756, 1.3862026705844126, 1.2719496963348844, 1.3489938748102903, 1.3780468374004164, 1.3884878389662338, 1.3352682241994538, 1.3348722240568909, 1.3921944407986777, 1.0476833161122294, 1.0845460746754008, 1.344165352323966, 1.298548179079665, 1.1979240079667628, 1.3539078973394736, 1.3187287426697725, 1.082794576116595, 1.3779471642491719, 1.3771347858434184, 1.3921944407986777, 1.193793081523992, 1.362050393265006, 1.076638744462226, 1.3551174562135766, 1.3393693468578751, 1.2470361076952952, 1.3696023478216113, 1.3750969645841487, 1.2964734722088322, 1.2953476417603207, 1.2470361076952952, 1.382661263313539, 1.3862026705844126, 1.3771240109822156, 1.25443884328785, 1.3136690818105938, 1.3853832858443051, 1.3486351838160378, 1.348026557887345, 1.0604869883721861, 1.3352682241994536, 1.3480480718535308, 1.3363233390543028, 1.154658436584056, 1.3921944407986775, 1.1979240079667626, 1.3620503932650059, 1.0881358731694244, 1.369042518200626, 1.3532766470312723, 1.2890012831575908, 1.3735565244300663]

and

y = [1.1262991662205104, 1.3136690818105938, 1.0446033225080773, 1.3551174562135764, 1.3032310852634252, 1.3806258468851462, 1.2270612333345983, 1.2719496963348844, 1.3601566259413194, 1.3756888280688913, 1.3475322202511097, 1.1937930815239919, 1.0510872606482404, 1.3441653523239654, 1.359738761905118, 1.3382152957887032, 1.0766387444622263, 1.1937930815239919, 1.0820779503060238, 1.1448104521200428, 1.3853832858443051, 1.28757746537949, 1.298548179079665, 1.067255392172351, 1.3168701741293156, 1.3910905417259205, 1.2908594990421354, 1.3750969645841487, 1.329688765445783, 1.386649365275275, 1.285486511663053, 1.2566273460024566, 1.323664826995234, 1.3862730319705538, 1.049346328049449]

which produce minDelta = 1.11022302462516E-016",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-02-28 23:39:06.704,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Mar 07 12:26:26 UTC 2017,,,,,,,"0|i3ar5z:",9223372036854775807,,,,,,,,,,,,,,,,"28/Feb/17 21:55;dfinkel;A temporary solution I've found is, in fixTies(), pulling the RealDistribution Object creation inside the do-while loop, and doubling the minDelta with every iteration until it's large enough:

{code}
do {
            LOGGER.warn(""using minDelta: {}"", minDelta);
            // Add jitter using a fixed seed (so same arguments always give same results),
            // low-initialization-overhead generator
            final RealDistribution dist = new UniformRealDistribution(new JDKRandomGenerator(100), -minDelta, minDelta);

            jitter(x, dist);
            jitter(y, dist);
            ties = hasTies(x, y);
            ct++;
            minDelta *= 2;
        } while (ties && ct < 1000);
{code}","28/Feb/17 23:39;erans;Thanks a lot for the report.

Could you create patches against the ""master"" branch? I.e.
* set up the example as a Junit test case (and check that it fails with the development version of the library),
* insert your proposed fix (see below)

By ""temporary solution"", do you mean that there could be problem in adopting it?

I'd suggest to instantiate the RNG outside the loop, as follows (see http://commons.apache.org/rng and the distribution class in the development version of Commons Math)
{code}
import org.apache.commons.rng.UniformRandomProvider;
import org.apache.commons.rng.simple.RandomSource;
// ...
final UniformRandomProvider rng = RandomSource.create(RandomSource.TWO_CMRES);
do {
      final RealDistribution.Sampler sampler =
          new UniformRealDistribution(-minDelta, minDelta).createSampler(rng);
      jitter(x, sampler);
      jitter(y, sampler);
      ties = hasTies(x, y);
      ct++;
      minDelta *= 2;
} while (ties && ct < 1000);
{code}

Since {{jitter}} is private and used for this single purpose, it would probably be better, performance-wise, to modify it to use the RNG directly; its signature would thus become:
{code}
private static void jitter(double[] data, UniformRandomProvider rng, double delta) {
    for (int i = 0; i < data.length; i++) {
        final double d = delta * (2 * rng.nextDouble() - 1);
        data[i] += d;
    }
}
{code}
","01/Mar/17 17:42;dfinkel;By ""temporary solution"" I only meant it as a workaround until an optimal solution would be introduced in the next release. I'm working on a patch right now. Should have a PR up soon with your proposed solution.","01/Mar/17 20:29;dfinkel;PR created https://github.com/apache/commons-math/pull/55","02/Mar/17 14:26;erans;Thanks.
Changes applied to ""master"" in commit 98055455265c04cf7f7a354bdc7aeac428730c5d

However, I believe that this issue cannot be resolved as such.
Indeed, the bound for the ""ct"" variable seems much too large (as it implies that the jitter value could grow up to minDelta * 2^1000).","02/Mar/17 14:43;dfinkel;Fortunately, it is inside of a do-while, so it should exit as soon as the minDelta gets large enough.
What maximum value of ""ct"" do you think would be best? 100? I have personally tested data that requires at least 8 loops before a significant minDelta is reached, so I wouldn't want to make the value too small.

Also, you wrote ""Changes applied to ""master"" in commit 98055455265c04cf7f7a354bdc7aeac428730c5d"" but I'm not sure what that means. Github is telling me ""master"" hasn't been updated in 6 days, I couldn't find the commit you referenced with a search, and the commit I submitted for review is ""18f181ada7826542725fa4a9460307d606695b5d""","02/Mar/17 15:16;erans;bq. Fortunately, it is inside of a do-while, so it should exit as soon as the minDelta gets large enough.

Sure, but it looks wrong for the code to hint that 1000 might be necessary.

bq. I have personally tested data that requires at least 8 loops before a significant minDelta is reached, so I wouldn't want to make the value too small.

Sure.
Could you make up a unit test that requires that many loops?

bq. you wrote ""Changes applied to ""master""

Yes, I forgot to ""push""! Sorry.","03/Mar/17 17:02;dfinkel;After further testing I've found a few more edge cases and determined the maximum possible value for the max iterations to be 2048, as opposed to 1000, since the exponent can be expressed in 11 bits. Here is a test I created that shows this.
{code}
    @Test
    public void testTwoSampleWithManyTiesAndExtremeValues_ManyAttempts() {
        final double[] largeX = {
                Double.MAX_VALUE, Double.MAX_VALUE,
                1e40, 1e40, 2e40, 2e40, 
                1e30, 2e30, 3e30, 4e30,
                5e10, 6e10, 7e10, 8e10};
        
        final double[] smallY = {
                Double.MIN_VALUE, (2 * Double.MIN_VALUE), 
                1e-40, 1e-40, 2e-40, 2e-40,
                1e-30, 2e-30, 3e-30, 4e-30,
                5e-10, 6e-10, 7e-10, 8e-10};
        
        // these values result in an initial calculated minDelta of 4.9E-324 (Double.MIN_VALUE),
        // but after 2046 iterations, the delta increases to 1.9958403095347198E292

        final KolmogorovSmirnovTest test = new KolmogorovSmirnovTest();
        Assert.assertEquals(0.63548496, test.kolmogorovSmirnovTest(largeX, smallY), 1e-6);
    }
{code}

There is also separate bug that can occur if there are two instances of Double.NaN, which are treated as a tie but can never be resolved through ""jiggling"" with a minDelta. I would suggest throwing a descriptive Exception if a NaN is passed into the KS test, instead of waiting for the loop to run through its iterations and throw a MathInternalError.

The last bug I found occurs if there are ties in the data and the minDelta is equal to Double.MIN_VALUE. At line 1154 in fixTies(), we divide the minDelta by 2, which in this case results in a new minDelta of 0... My method of iteratively doubling the minDelta becomes no longer viable. However, this can easily be resolved by adding an extra line right after:
{code}
 minDelta = Math.max(minDelta, Double.MIN_VALUE);
{code}","04/Mar/17 00:38;erans;bq. after 2046 iterations, the delta increases to 1.9958403095347198E292

So it looks to me that the code will then produce nonsense (changing the data so that it has nothing to do with the original).

bq. largeX ... smallY

Is there any chance that these two sequences come from the same distribution?

bq. Assert.assertEquals(0.63548496, test.kolmogorovSmirnovTest(largeX, smallY), 1e-6);

Where does the expected value come from?

bq. The last bug I found occurs if there are ties in the data and the minDelta is equal to Double.MIN_VALUE.

Agreed.
Could you set up a separate unit test for such a case?","04/Mar/17 13:58;erans;Could you please review the following suggested changes to {{hasTies}}, {{fixTies}} and {{jitter}}?

{code}
private static boolean hasTies(double[] x, double[] y) {
   final double[] values = MathArrays.unique(MathArrays.concatenate(x, y));
   if (values.length == x.length + y.length) {
       return false;  // There are no ties 
   }

   return true;
}
{code}

{code}
private static void fixTies(double[] x, double[] y) {
    if (hasTies(x, y)) {
        // Add jitter using a fixed seed (so same arguments always give same results),
        // low-initialization-overhead generator. 
        final UniformRandomProvider rng = RandomSource.create(RandomSource.TWO_CMRES, 7654321);

        // It is theoretically possible that jitter does not break ties, so repeat
        // until all ties are gone.  Bound the loop and throw MIE if bound is exceeded.
        int ct = 0;
        boolean ties = true;
        do {
            jitter(x, rng, 10);
            jitter(y, rng, 10);
            ties = hasTies(x, y);
            ++ct;
        } while (ties && ct < 10);
        if (ties) {
            throw new MathInternalError(); // Should never happen.
        }
    }
}
{code}

{code}
private static void jitter(double[] data,
                           UniformRandomProvider rng,
                           int ulp) {
    for (int i = 0; i < data.length; i++) {
        final int rand = rng.nextInt(ulp * 2) - ulp;
        data[i] += rand * Math.ulp(data[i]);
    }
}
{code}
","06/Mar/17 14:43;dfinkel;I like this solution a lot; I didn't even know a Math.ulp() method existed, but that makes a lot more sense for this use case, and significantly reduces the lines of code.

What are your thoughts on throwing an exception in the case of two NaNs appearing in the data, as no amount of jittering could resolve that tie, and a MathInternalError wouldn't be descriptive enough?

Also, why switch the RandomSource from JDK to TWO_CMRES?","07/Mar/17 12:26;erans;bq. I like this solution a lot

Great. :)

All proposed changes are now in ""master"" (commit b0b23c179ac55334f760aa29fce262c73a909268).

bq. Also, why switch the RandomSource from JDK to TWO_CMRES?

See [Commons RNG|http://commons.apache.org/proper/commons-rng/userguide/rng.html#a4._Performance]: {{RandomSource.JDK}} is only for reference purpose, but any of the other alternatives is better, performance-wise and/or quality-wise.
",,,,,
Incorrect calculation at BigFraction's doubleValue and floatValue,MATH-1402,13041676,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Won't Fix,,sushakov,sushakov,09/Feb/17 11:56,19/Mar/17 17:48,20/Mar/20 20:34,19/Mar/17 17:48,3.6.1,4.0,,,,,,0,,,,,"h1. Problem
* BigFraction#doubleValue produces incorrect result ""Infinity"" when numerator's value exceeds primitive double capacity, but denominator not
* Same relates to floatValue",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-02-09 12:28:04.883,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Mar 19 17:48:54 UTC 2017,,,,,,,"0|i39uc7:",9223372036854775807,,,,,,,,,,,,,,,,"09/Feb/17 12:11;sushakov;PR opened at github:
* https://github.com/apache/commons-math/pull/50
* https://github.com/apache/commons-math/pull/51","09/Feb/17 12:28;erans;The ""fraction"" functionality has just been moved to the (new) ""Commons Numbers"" project:
https://github.com/apache/commons-numbers

Please move this issue to the corresponding JIRA project:
https://issues.apache.org/jira/browse/NUMBERS

Thanks for the report!
","19/Mar/17 17:48;erans;Code is deprecated (to be replaced by module {{commons-numbers-fraction}} in new ""Commons Numbers"" project.
Issue has been [duplicated|https://issues.apache.org/jira/browse/NUMBERS-15] and fixed there.",,,,,,,,,,,,,,
"Overflows in ""UniformIntegerDistribution""",MATH-1396,13021524,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,erans,erans,erans,17/Nov/16 17:24,23/Nov/16 12:56,20/Mar/20 20:34,23/Nov/16 12:56,3.6.1,,,,,4.0,,0,,,,,"In {{o.a.c.m.distribution.UniformIntegerDistribution}}, several methods will compute an invalid result when the {{lower}} and {{upper}} bounds are such that
{noformat}
upper - lower
{noformat}
overflows.

Affected methods:
* {{probability}}
* {{cumulativeProbability}}
* {{getNumericalVariance}}

Method
* {{getNumericalMean}}

will return an invalid result when
{noformat}
upper + lower
{noformat}
overflows.

A possible fix is to define instances variables
{noformat}
upperPlusLower = (double) upper + (double) lower;
upperMinusLower = (double) upper - (double) lower;
{noformat}
and use them instead of the respective integer operations in the above methods.
",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 23 12:56:27 UTC 2016,,,,,,,"0|i36grj:",9223372036854775807,,,,,,,,,,,,,,,,"23/Nov/16 12:56;erans;commit af1b5872ab8355acea3197522ddf94972b3c8386",,,,,,,,,,,,,,,,
HypergeometricDistribution probability give NaN result,MATH-1356,12958453,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Major,Fixed,,tlacroix,tlacroix,13/Apr/16 12:27,06/Sep/16 06:48,20/Mar/20 20:34,06/May/16 21:31,3.6.1,,,,,4.0,,0,,,,,"Hi,
Unless I am mistaken the HypergeometricDistribution probability method returns NaN for the following cases :

HypergeometricDistribution hgd = new HypergeometricDistribution(11,11,1);
double probIT = hgd.probability(1);

HypergeometricDistribution hgd = new HypergeometricDistribution(11,11,11);
double probIT = hgd.probability(11);

I think it should return 1.0
Thanks,
Thomas",Windows,,,,,,,,,,,,,,,,"14/Apr/16 10:07;erans;MATH-1356.patch;https://issues.apache.org/jira/secure/attachment/12798698/MATH-1356.patch",,,,1.0,,,,,,,,,,,,,,,,,,,,2016-04-13 14:47:00.616,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 19 11:28:36 UTC 2016,,,,,,,"0|i2w21b:",9223372036854775807,,,,,,,,,,,,,,,,"13/Apr/16 14:47;erans;Bug(s) indeed:
* failing to check precondition(s) that lead to computing ""0 * infinity"", and/or
* failing to give the correct result in partcular cases (that throw off the implementation)

The NaN is created in {{SaddleExpansion.logBinomialProbability}} and {{SaddleExpansion.getDeviancePart}}.
Both perform a computation like the above.

Case
{noformat}
double probIT = hgd.probability(0);
{noformat}
also produces NaN.
","14/Apr/16 10:07;erans;I propose to commit the attached patch in branch ""feature-MATH-1158"" (since it contains modified versions, w.r.t. ""develop"" of the files in package {{o.a.c.math4.distribution}}).","19/Apr/16 11:28;erans;Commit pushed to branch ""feature-MATH-1158"".",,,,,,,,,,,,,,
LoessInterpolator can calculate median residual for robustness iterations incorrectly,MATH-1380,12983847,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,,,rwaj,rwaj,27/Jun/16 16:53,24/Dec/19 13:14,20/Mar/20 20:34,,3.6.1,,,,,4.X,,0,,,,,"When LoessInterpolator.smooth determines the median residual to use in weighting points when performing robustness iterations its calculation is only strictly correct for odd numbers of points. For even numbers it should take the mean of the central two residuals. While this may not generally make a large difference it hinders comparison with other implementations (such as R loess) for testing.

Patch and additional tests available.",,,,,,,,,,,,,,,,,"30/Jun/16 13:22;rwaj;MATH-1380-loess-residual-median.patch;https://issues.apache.org/jira/secure/attachment/12815456/MATH-1380-loess-residual-median.patch",,,,1.0,,,,,,,,,,,,,,,,,,,,2016-06-28 10:43:57.032,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 28 12:45:06 UTC 2016,,,,,,,"0|i3073j:",9223372036854775807,,,,,,,,,,,,,,,,"28/Jun/16 10:43;erans;Thanks for the report.

bq. Patch available with additional tests.

Please attach them to this page.
","28/Jun/16 11:18;erans;Could you make this patch against the development version?
It is in branch ""develop"" of the git repository.
Thanks.
","28/Jun/16 12:45;erans;Same comment as for MATH-1379.
",,,,,,,,,,,,,,
"In LogNormalDistribution.java, it appears shape & scale are reversed/mis-labelled.",MATH-1373,12974992,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Won't Fix,,kgierach,kgierach,02/Jun/16 00:27,02/Dec/19 08:08,20/Mar/20 20:34,02/Dec/19 08:08,3.6.1,,,,,4.0,,0,,,,,"When I compute the logshape and log scale based on the formulas on wikipedia's lognormal distribution page that use empirical mean and variance, I found that the getNumericalMean() method was not returning the empirical mean.

However, upon just trying to reverse the shape and scale parameters in the constructor proved to fix the problem, and the object then returns the correct empirical mean.

",,,,,3600,3600,,0%,3600,3600,,,,,,,"18/Jun/16 00:02;kgierach;MATH-1373.patch;https://issues.apache.org/jira/secure/attachment/12811492/MATH-1373.patch",,,,1.0,,,,,,,,,,,,,,,,,,,,2016-06-08 23:06:55.766,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 02 08:08:41 UTC 2019,,,,,,,"0|i2yuzj:",9223372036854775807,,,,,,,,,,,,,,,,"08/Jun/16 23:06;erans;Since there are many tests for this class, I wonder what the problem is.
Is it a documentation bug?

Would you provide a patch that would fix the issue?
","17/Jun/16 17:51;kgierach;The problem is that in the method shape & scale are simply reversed:
@Override
    public double getNumericalMean() {
        double s = shape;
        return FastMath.exp(scale + (s * s / 2));
    }

It should be:    FastMath.exp( shape + (scale * scale / 2 ) );
In any case here is a unit test code snippet that illustrates the problem:

        var defaultScale = 1.0; // aka variance
        var mean = 12.2;
        var meanSquared = mean * mean
        // compute sigma (log scale) parameter of the lognormal distribution.
        // according to formulas on Wikipedia
        var logScale = 
          Math.sqrt( 
                      Math.log( 1.0 + (defaultScale / meanSquared) )
                    )
        
        var logShape = Math.log( mean / 
                                 Math.sqrt( 1.0 + ( defaultScale / meanSquared ) ) 
                               )

        println( ""verifyLogNormalParms(): initializing with: scale/shape="" + logScale + "", "" + logShape )
        
        // parameter order according to api docs: scale      shape/location
        // here, parameters are reversed, and produce the correct result
        var dist = new LogNormalDistribution( logShape, logScale );
        
        var numMean = dist.getNumericalMean()
        
        if( Math.abs( numMean - mean ) > 0.01 ) {
          println( ""verifyLogNormalParms(): mean is NOT OK: "" + numMean  )
          assertTrue( false )
        }
        else {
          println( ""verifyLogNormalParms(): mean is OK: "" + numMean  )
        }","17/Jun/16 20:40;kgierach;I will come up with a patch based on github:  http://git-wip-us.apache.org/repos/asf/commons-math.git
Also, it appears the parameters are reversed in getNumericalVariance() as well.

Sound OK?

Thanks,
Karl","18/Jun/16 00:02;kgierach;this patch includes a revision to unit test which calcuates all expected shape and scale parameters based on the mean and variance of the unscaled data.","19/Jun/16 04:22;brentworden;I am not completely convinced this change is correct.

Referencing on of the citations, http://mathworld.wolfram.com/LogNormalDistribution.html, the density function is parameterized the same way LogNormalDistribution is parameterized with
* MathWorld's M being equivalent to Commons Math's scale
* MathWorld's S being equivalent to Commons Math's shape

The distribution mean according to MathWorld is Exp(M + S^2 / 2) which corresponds to Exp(scale + shape^2 / 2) and is how it is coded in LogNormalDistribution.

Likewise, MathWorld states the distribution variance Exp(S^2 + 2 M) * (Exp(S^2 - 1) which is Exp(shape^2 + 2 scale) * (Exp(shape^2 - 1).  Again, this matches the implementation.

Furthermore, generating a large sample from the distribution results in sample means and variances that are pretty close to the population values returned from the getNumericalMean and getNumericalVariance methods.  Here is the code I am using to make that claim:

{code}
    @Test
    public void testMeanAndVariance() {
        LogNormalDistribution dist = new LogNormalDistribution(5.375, 1.125);
        double[] x = new double[100000];
        for (int i = 0; i < x.length; ++i) {
            x[i] = dist.inverseCumulativeProbability(Math.random());
        }
        double actualMean = new Mean().evaluate(x);
        double actualVariance = new Variance().evaluate(x);

        double expectedMean = dist.getNumericalMean();
        double expectedVariance = dist.getNumericalVariance();

        System.out.println(String.format(""Mean: %f vs %f (actual vs expected)"", actualMean, expectedMean));
        System.out.println(String.format(""Variance: %f vs %f (actual vs expected)"", actualVariance, expectedVariance));
    }
{code}
","19/Jun/16 17:36;erans;I think that it's a documentation issue.

{quote}
* MathWorld's M being equivalent to Commons Math's scale
* MathWorld's S being equivalent to Commons Math's shape
{quote}

In [MathWorld|http://mathworld.wolfram.com/LogNormalDistribution.html], {{M}} and {{S}} above are respectively named {{mu}} and {{sigma}}.
But CM uses the names {{scale}} and {{shape}} (in that order), whereas [Wikipedia|https://en.wikipedia.org/wiki/Log-normal_distribution#Location_and_scale] refers to them as {{location}} and {{scale}} (in that order).

IIUC, CM uses the [NIST convention |http://www.itl.nist.gov/div898/handbook/eda/section3/eda3669.htm] (where {{sigma}} is referred to as {{shape}}) but the Javadoc links to sites that use other conventions.

The API  would be less confusing if we'd use {{meanLog}} (a.k.a. {{mu}} or {{scale}}) and {{standardDeviationLog}} (a.k.a. {{sigma}} or {{shape}}).

Do you agree?
","21/Jan/18 15:50;erans;Discussion should be moved to the issue tracker of the new ""Commons Statistics"" component (see STATISTICS-2).","02/Dec/19 08:08;erans;Class does not exist in ""Commons Math"" anymore (codes were ported to [""Commons Statistics""|http://commons.apache.org/statistics]).",,,,,,,,,
"cumulativeProbability of LevyDistribution returns NaN for values out of domain, while others return 0",MATH-1503,13269257,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Won't Do,,WFR,WFR,19/Nov/19 08:11,22/Nov/19 16:37,20/Mar/20 20:34,22/Nov/19 16:37,3.6.1,,,,,,,0,,,,,"LevyDistribution.cumulativeProbability returns Double.NaN for values that are outside of its domain (x < mu in this case), while GammaDistribution returns 0.0 (for x <= 0). Both cases are hard-coded.{color:#ffc66d}
{color}

A consistent behaviour would be desirable.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-11-22 16:37:06.599,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 22 16:37:06 UTC 2019,,,,,,,"0|z08rvc:",9223372036854775807,,,,,,,,,,,,,,,,"22/Nov/19 16:37;erans;Thanks for the report.  I made the change in the [""Commons Statistics"" project|http://commons.apache.org/proper/commons-statistics/] where the distributions now belong (most of the package {{o.a.c.m.stat.distribution}} has been moved there and will be removed from the next major version of Commons Math).

You are most welcome to review and test the ported code.",,,,,,,,,,,,,,,,
getNumericalVariance of LogisticDistribution is incorrect,MATH-1498,13256143,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,,,WFR,WFR,11/Sep/19 15:41,11/Sep/19 16:10,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"The variance of a logistic distribution returned by LogisticDistribution.getNumericalVariance() is incorrect:

It is computed by (MathUtils.{color:#9876aa}PI_SQUARED {color}/ {color:#6897bb}3.0{color}) * ({color:#6897bb}1.0 {color}/ ({color:#9876aa}s {color}* {color:#9876aa}s{color})){color:#cc7832};{color}

{color:#cc7832}it should be {color}(MathUtils.{color:#9876aa}PI_SQUARED {color}/ {color:#6897bb}3.0{color}) * ({color:#9876aa}s {color}* {color:#9876aa}s{color}){color:#cc7832};{color}

{color:#cc7832}Compare Wikipedia: https://en.wikipedia.org/wiki/Logistic_distribution{color}","Windows, Java 8",,,,7200,7200,,0%,7200,7200,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-09-11 16:10:40.971,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Sep 11 16:10:40 UTC 2019,,,,,,,"0|z06ju8:",9223372036854775807,,,,,,,,,,,,,,,,"11/Sep/19 16:10;aherbert;Thanks for the report.

The distributions in the most recent commons-math4 project have been moved to the new commons-statistics project. This code is currently unreleased and I have fixed the bug.
",,,,,,,,,,,,,,,,
Fraction.add(int) and Fraction.subtract(int) ignore risk of integer overflow,MATH-1484,13234118,Bug,Closed,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Won't Fix,,Schamschi,Schamschi,18/May/19 13:07,31/May/19 21:57,20/Mar/20 20:34,31/May/19 21:57,3.6.1,,,,,,,0,,,,,"The methods {{add(int)}} and {{subtract(int)}} in the class {{org.apache.commons.math4.fraction.Fraction.java}} do not take into account the risk of an integer overflow. For example, (2​^31^ - 1)/2 + 1 = (2​^31^ + 1)/2, so the numerator overflows an {{int}}, but when calculated with {{Fraction.add(int)}}, the method still returns normally.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2019-05-18 16:38:03.453,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat May 18 21:21:40 UTC 2019,,,,,,,"0|z02tow:",9223372036854775807,,,,,,,,,,,,,,,,"18/May/19 16:38;erans;Thanks for your report.
The [fraction functionality|https://gitbox.apache.org/repos/asf?p=commons-numbers.git;a=tree;f=commons-numbers-fraction] has been moved to the [""Commons Numbers""|https://commons.apache.org/proper/commons-numbers/] project.
Please move the issue to the corresponding [JIRA tracker|https://issues.apache.org/jira/projects/NUMBERS].

Patch, with unit tests, welcome.","18/May/19 20:51;Schamschi;OK, I actually had the issue fixed in my fork of the repository, I just didn't have time to create a pull request when I posted the issue here (it's my first time on Github, so I would have needed some time to make sure I do it correctly). Should I still create the pull request for this project? It seems to me that, if the class exists in this project, there is no reason not to fix the bug.","18/May/19 21:21;erans;bq. Should I still create the pull request for this project?

No; it should be fixed in ""Commons Numbers"".

bq. It seems to me that, if the class exists in this project, there is no reason not to fix the bug.

According to the current plan, this class won't exist in the next release of ""Commons Math"" (because, as said, the functionality has been moved already).",,,,,,,,,,,,,,
IntegerSequence.Incrementor should fail earlier,MATH-1460,13156671,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Fixed,erans,erans,erans,02/May/18 17:54,18/Jan/19 14:53,20/Mar/20 20:34,18/Jan/19 14:53,3.6.1,,,,,4.0,,0,,,,,Method {{increment(int nTimes)}} allows increment beyond the maximal value.,,,,,,,,,,,,,,,MATH-1458,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 02 18:02:17 UTC 2018,,,,,,,"0|i3t9rz:",9223372036854775807,,,,,,,,,,,,,,,,"02/May/18 18:02;erans;Tentative solution in commit f43069ac6d281b8367dad6f78def4b8336a11ff0 (please review).",,,,,,,,,,,,,,,,
Simpson Integrator computes incorrect value at minimum iterations=1 and wastes an iteration,MATH-1458,13156336,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Fixed,,aherbert,aherbert,01/May/18 13:56,18/Jan/19 14:52,20/Mar/20 20:34,18/Jan/19 14:52,3.6.1,,,,,,,0,documentation,easyfix,newbie,patch,"org.apache.commons.math3.analysis.integration.SimpsonIntergrator

When used with minimalIterationCount == 1 the integrator computes the wrong value due to the inlining of computation of stage 1 and stage 0 of the TrapezoidIntegrator. Each stage is successive since it relies on the result of the previous stage. So stage 0 must be computed first. This inlining causes stage 1 to be computed before stage 0:
{code:java}
return (4 * qtrap.stage(this, 1) - qtrap.stage(this, 0)) / 3.0;

{code}
This can be fixed using:
{code:java}
final double s0 = qtrap.stage(this, 0);
return (4 * qtrap.stage(this, 1) - s0) / 3.0;{code}
What is not clear is why setting minimum iterations to 1 results in no iteration. This is not documented. I would expect setting it to 1 would compute the first Simpson sum and then perform 1 refinement. This would make it functionality equivalent to the other Integrator classes which compute two sums for the first iteration and allow them to be compared if minimum iterations = 1. If convergence fails then each additional iteration computes an additional sum.

Note when used with minimalIterationCount > 1 the SimpsonIntegrator wastes a stage since it computes the following stages: 0, 0, 1, 2, 3. i.e. stage 0 is computed twice. This is because the iteration is incremented after the stage is computed:
{code:java}
final double t = qtrap.stage(this, getIterations());
incrementCount();
{code}
This should be:
{code:java}
incrementCount();
final double t = qtrap.stage(this, getIterations());
{code}
On the first iteration it thus computes the trapezoid sum and compares it to zero. This would  result in a bad computation if integrating a function whose trapezoid sum is zero (e.g. y=x^3 in the range -1 to 1). However since iteration only occurs for minimalIterationCount>1 no termination comparison is made on the first loop. The first termination comparison can be made at iteration=2 where the comparison will be between the Trapezoid sum and the first Simpson sum. This is a bug.

However I do not want to submit a formal patch as there is a lack of consistency across all the integrators in their doIntegrate() method with the use of incrementCount() and what the iteration number should be at the start of the while (true) loop:
 * IterativeLegendreGauss integrator uses getIterations()+1 to mark the current iteration inside the loop and calls incrementCount() at the end. 
 * TrapezoidIntegrator calls incrementCount() outside the loop, uses getIterations() to mark the current iteration and calls incrementCount() at the end.
 * The MidpointIntegrator calls incrementCount() at the start of the loop and uses getIterations() to mark the current iteration.
 * The RombergIntegrator calls incrementCount() outside the loop, uses getIterations() to mark the current iteration and calls incrementCount() in the middle of the loop before termination conditions have been checked. This allows it to fail when the iterations are equal to the maximum iterations even if convergence has been achieved (see Note*).
 * The SimpsonIntegrator uses getIterations() to mark the current iteration and calls incrementCount() immediately after.

Note*: This may not be discovered in a unit test since the incrementCount() uses a backing Incrementor where the Incrementor.increment() method calls Incrementor.increment(1) which ends up calling canIncrement(0) \{ instead of canIncrement(nTimes) } to check if the maxCountCallback should be triggered. I expect that all uses of the Incrementor actually trigger the maxCountCallback when the count has actually exceeded the maximalCount. I don't want to get into debugging that class since it also has an iterator using hasNext() with a call to canIncrement(0) and I do not know the contract that the iterator is working under.

A consistent approach would be:
 * Compute the first sum before the loop
 * Enter the loop and increment the iteration (so the first loop execution would be iteration 1)
 * Compute the next sum
 * Check termination conditions

An example for the SimpsonIntegrator is below:
{code:java}
protected double doIntegrate() throws 
  TooManyEvaluationsException, MaxCountExceededException
{
  // This is a modification from the default SimpsonIntegrator.
  // That only computed a single iteration if 
  // getMinimalIterationCount() == 1.

  // Simpson's rule requires at least two trapezoid stages.
  // So we set the first sum using two trapezoid stages.
  TrapezoidIntegrator qtrap = new TrapezoidIntegrator();

  final double s0 = qtrap.stage(this, 0);
  double oldt = qtrap.stage(this, 1);
  double olds = (4 * oldt - s0) / 3.0;
  while (true)
  {
    // The first iteration is now the first refinement of the sum.
    // This matches how the MidPointIntegrator works.
    incrementCount();
    final int i = getIterations();
    // 1-stage ahead of the iteration
    final double t = qtrap.stage(this, i + 1);
    final double s = (4 * t - oldt) / 3.0;
    if (i >= getMinimalIterationCount())
    {
      final double delta = FastMath.abs(s - olds);
      final double rLimit = getRelativeAccuracy() * 
        (FastMath.abs(olds) + FastMath.abs(s)) * 0.5;
      if ((delta <= rLimit) || (delta <= getAbsoluteAccuracy()))
      {
        return s;
      }
    }
    olds = s;
    oldt = t;
  }

}
{code}
Note: If this method is accepted then the SIMPSON_MAX_ITERATIONS_COUNT must be reduced by 1 to 63, since the stage method of the TrapezoidIntegrator has a maximum valid input argument of 64.

 ","openjdk version ""1.8.0_162""                                                                                                           
OpenJDK Runtime Environment (build 1.8.0_162-8u162-b12-0ubuntu0.16.04.2-b12)                                                          
OpenJDK 64-Bit Server VM (build 25.162-b12, mixed mode)    ",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-05-02 11:07:07.956,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue May 08 15:51:53 UTC 2018,,,,,,,"0|i3t7pr:",9223372036854775807,,,,,,,,,,,,,,,,"02/May/18 11:07;erans;Thanks a lot for the report and thorough analysis.
The next step would be to write a unit test that displays the bug. And then a patch/PR to fix it.
I don't follow the argument about {{Incrementor}} but please note that it is _deprecated_ in the development version of the library: updates/fixes should be performed against the ""master"" branch in the code repository.","02/May/18 11:43;aherbert;The comment about the Incrementor is for the new IntegerSequence.Incrementor not the deprecated org.apache.commons.math3.util.Incrementor.

I think the public void increment(int nTimes) method of IntegerSequence.Incrementor should be:
{code:java}
public void increment(int nTimes) throws MaxCountExceededException {
  if (nTimes <= 0) {
    throw new NotStrictlyPositiveException(nTimes);
  }

  // This is a change from: if (!canIncrement(0)) {
  if (!canIncrement(nTimes)) {
    maxCountCallback.trigger(maximalCount);
  }
  count += nTimes * increment;
}
{code}
Since I am new to this please allow some naive questions. I assumed that a core developer would be able to look at this and I had contributed enough. Are you saying that I have to provide the patch?","02/May/18 18:17;erans;I've created issue MATH-1460. Please have a look.
{quote}I assumed that a core developer would be able to look at this and I had contributed enough. Are you saying that I have to provide the patch?
{quote}
We are lacking time and expertise to support all the code in this library. We've started to split it in more manageable parts that can be maintained more easily by people not necessarily able to fix all the issues that keep coming for Commons Math and prevent timely releases.

See the new components [Commons RNG|http://commons.apache.org/rng], [Commons Numbers|http://commons.apache.org/numbers], [Commons Statistics|http://commons.apache.org/statistics], [Commons Geometry|http://commons.apache.org/geometry], ... that are at various stages of completion.

You are most welcome to contribute to e.g. a new module in ""Commons Numbers"" that could contain selected parts of the code currently in package {{org.apache.commons.math4.analysis}}.","03/May/18 10:45;aherbert;I've branched the git repo and will create tests that the current SimpsonItegrator fails. I'll then fix it and submit a pull request for review.","08/May/18 09:55;aherbert;Changes submitted via the pull request:

[MATH-1458|https://github.com/apache/commons-math/pull/85]

 ","08/May/18 11:08;erans;Hi.
Thanks for the patch.
Sorry for the nit-pick, but please run
{noformat}
$ mvn site
{noformat}
and check that it did not introduce any CheckStyle errors (the generated site, with the reports, will be under the {{target/site}} directory).","08/May/18 12:32;aherbert;Found 1 checkstyle error for trailing whitespace.

I was careful to never use a code formatting tool and followed the guideline here:

[CONTRIBUTING|https://github.com/aherbert/commons-math/blob/master/CONTRIBUTING.md]

I ran
{code:java}
mvn clean verify
{code}
but did not know about 
{code:java}
mvn site
{code}
It now all builds with no errors. ","08/May/18 15:51;erans;Merged (commit 36553ffab375518a8ce39b25a916f730775435a4 on ""master"").",,,,,,,,,
Unreachable statements in Complex.abs(),MATH-1427,13092055,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Won't Fix,,David Nickerson,David Nickerson,03/Aug/17 02:34,21/Jan/18 15:28,20/Mar/20 20:34,21/Jan/18 15:28,3.6.1,,,,,,,0,easyfix,newbie,patch,,"This return statement in Complex.abs() is unreachable:

{code:java}
if (FastMath.abs(real) < FastMath.abs(imaginary)) {
  if (imaginary == 0.0) {
    return FastMath.abs(real);
  }
{code}

If imaginary == 0, then there's no way that the preceding condition would be true. There are two similar inner 'if' statements that were accidentally switched. Returned values are still correct, but performance suffers.

The attached patch switches these back. Note that we're still protected from dividing by zero.
",,,,,,,,,,,,,,,,,"03/Aug/17 02:35;David Nickerson;complex_abs.patch;https://issues.apache.org/jira/secure/attachment/12880153/complex_abs.patch",,,,1.0,,,,,,,,,,,,,,,,,,,,2017-08-03 11:06:28.783,,,false,,,,,,,,,,Patch,,,,,,,,9223372036854775807,,,Sun Jan 21 15:28:56 UTC 2018,,,,,,,"0|i3icov:",9223372036854775807,,,,,,,,,,,,,,,,"03/Aug/17 11:06;erans;The ""complex number"" functionality is being refactored within a new project: http://commons.apache.org/proper/commons-numbers/

You are most welcome to review the changes, currently performed within the [""complex-dev"" branch|https://git1-us-west.apache.org/repos/asf?p=commons-numbers.git;a=tree;h=0a01e2d0e7e6c6621cbf6b5c2c7da885c1691c07;hb=0a01e2d0e7e6c6621cbf6b5c2c7da885c1691c07] and to provide suggestions on the ""dev"" ML.

Please report issues at
https://issues.apache.org/jira/projects/NUMBERS
","03/Aug/17 17:19;David Nickerson;Bug report migrated to [https://issues.apache.org/jira/browse/NUMBERS-48]","21/Jan/18 15:28;erans;See NUMBERS-48.",,,,,,,,,,,,,,
Complex.ZERO.pow(2.0) is NaN,MATH-1397,13022247,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Won't Do,ericbarnhill,maweki,maweki,21/Nov/16 17:16,01/May/17 23:41,20/Mar/20 20:34,01/May/17 23:41,3.6.1,,,,,4.0,,1,,,,,"```
package complextest;

import org.apache.commons.math3.complex.Complex;

public class T {
	public static void main(String[] args) {
		System.out.println(Complex.ZERO.pow(2.0));
	}
}
```

This is the code and the readout is `(NaN, NaN)`. This surely isn't right. For one, it should actually be zero (https://www.wolframalpha.com/input/?i=(0%2B0i)%5E2) and second of all, the documentation doesn't state that anything could go wrong from a Complex number that has no NaNs and Infs.

The other definition states that it doesn't work when the base is Zero, but it surely should. This strange corner case destroys any naive implementation of stuff wrt the mandelbrot set.

It would be nice to not have to implement this exception myself.","Linux, Java1.7/Java1.8",,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-01-02 16:35:34.774,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon May 01 23:41:57 UTC 2017,,,,,,,"0|i36l87:",9223372036854775807,,,,,,,,,,,,,,,,"02/Jan/17 16:35;raydecampo;Added a pull request to implement the case of 0 raised to a real positive number:

https://github.com/apache/commons-math/pull/47
","02/Jan/17 23:31;erans;Hello Mario and Raymond.

Having complex numbers (and related functionality) in their own component was on the roadmap; an effort led by Eric Barnhill (to whom I've just assigned this issue).
If you'd like to help move the code out of Commons Math, please post to the ""dev"" ML.

Thanks for the report.
","27/Apr/17 07:14;wilbur;I am not sure what the status of this issue is (apparently has been unsolved for years), but this is an URGENT PROBLEM and should be fixed soon!

I told my students to use a ""proven"" libary instread of doing their own implementation of 'Complex' and the first thing they run across is this bug. What should I tell them now? Surprisingly, the (NaN, NaN) outcome is intended (even checked in a test case!), although I do not know of any other environment with a similar behaviour.

Why is the pow() based on the log() in the first place? Wouldn't it be simpler to perform exponentiation in polar form, without the 0-singularity?

--Wilhelm","27/Apr/17 12:41;erans;bq. status of this issue

It has been fixed in the new [""Commons Numbers"" project|http://commons.apache.org/proper/commons-numbers] (see NUMBERS-4).
The {{complex}} package will not be part of the next release of Commons Math.

bq. I told my students to use a ""proven"" library

I totally agree.

bq. first thing they run across is this bug.

I'm very sorry.
It shows that even after many years, there is still room for improving supposedly mature code.

bq.  What should I tell them now?

Please tell them that they are most welcome to test and review the code, to provide comments and suggestions, and participate in the development by filing bug reports and fixing bugs.

""Commons Numbers"" is being actively worked on right now.
I hope that we are able to produce the first official release in the coming weeks.

The new (non-official) artefacts for the ""complex"" functionality can downloaded from the [snapshot repository|https://repository.apache.org/content/repositories/snapshots/org/apache/commons/commons-numbers-complex/1.0-SNAPSHOT/].

bq. I do not know of any other environment with a similar behaviour.

You are quite right.
Eric Barnhill is leading the refactoring, with the explicit goal to make the behaviour conform to the ISO standard.
I'm sure that he'll welcome your help. If not done already, please subscribe to the ""dev"" ML in order to discuss the features which you expect from an implementation of the concept of ""complex numbers"".

bq. Wouldn't it be simpler to perform exponentiation in polar form

I certainly agree.
I had a, perhaps naive, proposal aimed at ensuring that the most effective algorithm would be used for a given computation: see https://issues.apache.org/jira/browse/NUMBERS-10
Please let us know what you think.","27/Apr/17 14:10;wilbur;Hello Gilles, thanks for your enlightening comments. I'd be happy to help if I can (i.e., add anything to the outstanding experts' work). I have seen the recent patch for the pow() method by Raymond and wondered if there was an accessible (and complete) GIT repo for the ""Commons Numbers"" project. I tried to build the subproject but could not find the associated parent project (POM).

--Wilhelm","27/Apr/17 14:31;erans;Did you proceed as indicated [here|http://commons.apache.org/proper/commons-numbers/source-repository.html]?

From the top directory, running
{noformat}
mvn clean package
{noformat}
should create all the artefacts (to be found in each module's ""target"" subdirectory).
","27/Apr/17 16:26;wilbur;Thanks - no, I had looked in the wrong place at [""Source code repository (current)"" | http://git-wip-us.apache.org/repos/asf/commons-rng.git] and did not realize the other menu entry further down.

I was able to clone and build the complete repo (with command-line mvn) successfully. However, importing into Eclipse gave me a couple of errors (apparently related to the maven-antrun-plugin and checkstyle) which I could not resolve, e.g. (for every pom.xml on line 23):

{noformat}
Plugin execution not covered by lifecycle configuration: org.apache.maven.plugins:maven-antrun-plugin:1.7:run (execution: javadoc.resources, phase: generate-sources)
pom.xml	/commons-numbers-complex	line 23
{noformat}

Any hints appreciated...","27/Apr/17 16:41;ericbarnhill;Welcome Wilhelm!

I actually found it so fragile, to integrate Eclipse and Maven with a Git project, that I gave up Eclipse and learned how to code Java using personalized Vim. I realize this is not much of a hint.

I am currently working to conform Complex to the ISO C standard. If you know the standard you know there are a great many behaviors to check, and Java only does some of them inherently, so it has turned into a pretty large project. You should feel free to fix any behaviors you don't like on your own branch and I will integrate them.

As for using the polar representation for certain operations, I certainly have no objection in principle. The ISO standard is defined completely in terms of real and imaginary, including a great many equivalence relationships that I need to test. Thinking about how to re-define every branch cut in polar coordinates is more than I can commit to and would be prone to error. Also, libraries that provide useful trig formulas like Complex.js provide them all in terms of real and imaginary and reconstructing these in polar would also be prone to error.

 cpow() is covered in G.6.4.1 and actually has no branch cuts so you should go ahead; however you can see from G.6.3.2 that we could not do clog() the same way.
","27/Apr/17 20:21;wilbur;Hello Eric, 

thanks for this update. I have used Eclipse for all my projects over many years with good success. However, I agree that Maven support is brittle, so I have been considering to switch to IntelliJ as an alternative for quite a while now. As a first test, I tried it on the 'commons-number' project and it importet without any glitch. Looks good!

Thanks for the invitation to participate in this project, I'll be happy to look into it and see where I can help. Note however that, while I do have a CS background, I am not a mathematician (hobbyist at best) ...

--Wilhelm","01/May/17 23:41;erans;Issue moved to ""Commons Numbers"", and fixed there.",,,,,,,
BOBYQAOptimizer Seems to Sometimes Enter Endless Loop,MATH-1375,12977081,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,,,thomasWeise,thomasWeise,09/Jun/16 02:59,18/Apr/17 15:47,20/Mar/20 20:34,,3.6.1,,,,,4.0,,0,,,,,"I am using BOBYQAOptimizer to solve some numerical problems related to nonlinear function fitting. BOBYQAOptimizer is provided with close-to-optimal solutions which it is supposed to refine. In some cases, BOBYQAOptimizer seems to enter an endless loop, or at least an extremely long loop. The problem is almost impossible to reproduce as it occurs maybe once every 1000 runs.

From what I can see with the debugger, the source of the problem is probably method trsbox which is called by bobyqb. In trsbox, some values of a vector (sorry, forgot which one) grow extremely large (>=1e250). Either way, I noticed that both mentioned methods feature a for(;; ) loop.

Now that algorithm looks quite mathematical to me and seemingly has been translated from FORTRAN or something. I think fixing and finding mathematical issues might be complicated (see also the caveats reported in the release notes) and overall, the algorithm is working.

How about you also count the iterations of the for(;; ) loops in bobyqb and trsbox and throw an exception if they exceed some limit? In the easiest case, instead of for(;; ) you can do something like

{code}
for(int maxRemainingSteps=100; (--maxRemainingSteps)>=0;) {
...
}
   throw new MaxCountExceededException(100);
// or TooManyEvaluationsException(100);
// or MathIllegalStateException(LocalizedFormats.SIMPLE_MESSAGE, ""Huh?"");
{code}

Since the original for loops are always left via ""return"", that would already do the trick. Or you could use an Incrementor object for this purpose. Either way, I think with the very simple fix above, you would prevent endless loops, add only a tiny bit of very easy-to-understand code, and would not break the algorithm contract, since such exceptions could be thrown sometimes even without the fix.

In summary: BOBYQAOptimizer needs some work. Fixing the issue I observed properly (i.e., by fixing the special cases causing it) is probably very complex and is probably not feasible. Preventing it, however, seems to be rather easy, as I have shown above.","Java 8 JDK, OpenJDK, Ubuntu",,,,14400,14400,,0%,14400,14400,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2016-06-09 10:24:33.339,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 16 21:00:27 UTC 2016,,,,,,,"0|i2z74n:",9223372036854775807,,,,,,,,,,,,,,,,"09/Jun/16 10:24;erans;I've linked related issues.

The first one seems to be the same problem which you report; perhaps the second one is the cause of it.  Could you please look at it, and confirm whether it can have an impact?

If so, you are most welcome to provide a patch.

Side questions:
* Did you try other optimizers?
* Did you try another implementation of BOBYQA?","11/Jun/16 11:37;thomasWeise;Hi. Yes, MATH-1282 is definitely related, probably the same problem.

I am using BOBYQA in combination with other optimizers. I found that in my particular problem, Levenberg-Marquardt + Nelder/Mead + BOBYQA in combination often give the best performance/runtime results.

I did not test other implementations of BOBYQA. I see where you are getting at: This problem seems to only occur rarely, it might actually already be present in the original algorithm.

From this perspective, my suggested fix may be the best option for the time being: Limiting the loops to a reasonable, generous maximum number of iterations. The main issue is this: The problem does not occur often, the other issue confirms that. If the problem occurs, this is an endless loop. So for a productive system, this is a real show stopper. Since the problem does not occur often, it would even be acceptable if BOBYQA would run quite a bit longer, as long as it does not run forever. Thus the idea with the generous upper limit. trsbox could simply return null is the limit is exceeded, which could be checked in the calling method, which could then simply return immediately as well. One could even allow the user to specify the limit number.

The resulting changes in code would be minimal and they would not violate the contract of the methods. BOBYQA cannot guarantee to find the global optimum anyway. If in some very rare cases it would be terminated ""early"" after quite some time while it was actually not in an endless loop, it could return the best-so-far solution, which would then probably not be very different from what it would return anyway.","11/Jun/16 14:55;ggregory;The loop count would need to be configurable IMO.

An alternative would be for the loops to check once in a while if the current thread has been interrupted.

Having an SME look over the sctual algorithm would be best of course.","13/Jun/16 02:06;thomasWeise;I agree, it should be configurable, with a reasonably-large default: One could run several tests on existing problems (Maybe there already are some unit tests or something?), check the largest number of iterations ever encountered in the problematic methods, then multiply with 1000. This would be a good default maximum loop count. Users would be extremely unlikely to experience any difference in performance and results. (And even if they would, the changes should be extremely small. And even if they were not, this would still be within the contract of the methods, as result quality and discovery of optima is not guaranteed anywhere.)

Regarding the second option, checking for interruption: I think that one would be less desirable. So far, two issues have reported/confirmed that bug. Thus, if one would build a productive system, currently, BOBYQA would not be an option, as it might hang - and nobody knows why. So the issue should be fixed. If we would fix it with checking for interruption, this would mean that whenever we use BOBYQA, we need to start another thread, wait for, say, 10 minutes, and then interrupt. This would be a completely different scenario from what is done so far and also completely different from how the other algorithms behave. The required changes in code that uses or would use BOBYQA would be much more severe than with the maximum loop counter option.

From this perspective, it would - in my opinion - even be more feasible to provide a ""maximum runtime"" in ms and have methods check System.currentTimeMillis() from time to time. Such an option may actually even be better than having a maximum iteration limit, as it currently exists. Reason: Most algorithms support an iteration limit, but the runtime per iteration may differ extremely from algorithm to algorithm. The users currently cannot really know how much runtime an algorithm will take if they say ""at most 1000 iterations"", for instance. However, I think what most users actually want is to limit the runtime - so why not do it in a natural way, by letting them specify a time limit in ms? Hm ... that would actually be a feature request... ","16/Nov/16 16:11;burton;Have you tried reducing the stopping trust region radius?  I have encountered optimization problems where BOBYQA consistently hit the evaluation limit with a stopping trust region radius of 1e-8, but finished in a reasonable time with 1e-6.","16/Nov/16 21:00;thomasWeise;If I remember correctly, the two loops do not check any evaluation limit. This bug is _not_ about the optimization failing with bad results or throwing an exception. It is about the algorithm going into an endless loop. A loop from which it will never return. And such a loop must be impossible in any productive environment.

In a productive environment, you often cannot control the exact features of the optimization problem you want to solve. It could be a problem which normally can be solved well with certain setups but the same problem may also have instances with a configuration where that is not possible.

Thus my suggestion to either limit the iteration numbers of these loops or to throw an exception if they iterate too long. Fixing this issue will probably just cost 30 minutes of programming. And the suggested changes will have no impact in scenarios where the algorithm works well (or at least does not loop forever). Only in the border cases where it loops forever, they will kick in.",,,,,,,,,,,
SimplexOptimizer.doOptimize(): Wrong Iteration Number (0) Passed to Convergence Checker,MATH-1376,12977856,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Minor,Fixed,,thomasWeise,thomasWeise,11/Jun/16 12:38,11/Jun/16 19:31,20/Mar/20 20:34,11/Jun/16 19:31,3.6.1,,,,,4.0,,0,Convergence,Iterations,SimplexOptimizer,,"The convergence checker used in method doOptimize() of SimplexOptimizer always receives 0 as iteration counter. This can very easily be fixed. Check this out:

Original (with added comments):

{code}
int iteration = 0; // XXXXXXXXX set to zero and never update
        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();
        while (true) {
            if (getIterations() > 0) {
                boolean converged = true;
                for (int i = 0; i < simplex.getSize(); i++) {
                    PointValuePair prev = previous[i];
                    converged = converged && // XXXXXXXXX ouch below
                        checker.converged(iteration, prev, simplex.getPoint(i));
                }
                if (converged) {
                    // We have found an optimum.
                    return simplex.getPoint(0);
                }
            }
{code}

should be (with added comments)

{code}
int iteration = 0;
        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();
        while (true) {
            iteration = getIterations(); // XXXXXXXX CHANGE 1
            if (iteration > 0) {  // XXXXXXXX CHANGE 2
                boolean converged = true;
                for (int i = 0; i < simplex.getSize(); i++) {
                    PointValuePair prev = previous[i];
                    converged = converged &&
                        checker.converged(iteration, prev, simplex.getPoint(i));
                }
                if (converged) {
                    // We have found an optimum.
                    return simplex.getPoint(0);
                }
            }
{code}",,,,,1200,1200,,0%,1200,1200,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2016-06-11 19:31:43.399,,,false,,,,,,,,,,Patch,,,,,,,,9223372036854775807,,,Sat Jun 11 19:31:43 UTC 2016,,,,,,,"0|i2zbwn:",9223372036854775807,,,,,,,,,,,,,,,,"11/Jun/16 19:31;erans;Fix applied in branch ""develop"".
Thanks for the report.",,,,,,,,,,,,,,,,
developers documentation not generated correctly,MATH-1511,13281587,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Trivial,Fixed,,claude,claude,26/Jan/20 10:50,10/Mar/20 18:00,20/Mar/20 20:34,10/Mar/20 18:00,3.6.1,,,,,4.0,,0,,,,,"The Documentation subsection of the developers.xml file attempts to document how to add formula to javadoc.  However, the special characters patterns used to trigger the mathjax engine are triggering engine and converting the surrounding code to math formatted text.

 

the character patterns in question are 
{{\(}}

\)

\[

\]

 ",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2020-03-10 18:00:48.335,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Mar 10 18:00:48 UTC 2020,,,,,,,"0|z0av88:",9223372036854775807,,,,,,,,,,,,,,,,"10/Mar/20 18:00;erans;Commit af4962c3c6c3ee7b322177b50219062dd3b76d9b (""master"" branch).
Thanks for the report.",,,,,,,,,,,,,,,,
mathjax CDN shutting down,MATH-1510,13281586,Bug,Open,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Trivial,,,claude,claude,26/Jan/20 10:44,26/Jan/20 15:25,20/Mar/20 20:34,,3.6.1,,,,,,,0,,,,,"This is the as https://issues.apache.org/jira/browse/NUMBERS-36 from which this text is lifted.  I noticed the issue in the site.xml file.

 

Javadoc for Commons Math, Commons Numbers and friends use a the [MathJax|https://www.mathjax.org/] Javascript in order to render LaTeX equation within Javadoc. (See MATH-1006)

This used to be included as [http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML] – but now [cdn.mathjax.org is shutting down|https://www.mathjax.org/cdn-shutting-down/]. There is a temporary redirect.

There are several alternatives suggested, with the recommended being:
{code:java}
<script type=""text/javascript"" async
  src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?..."">
</script>
{code}
Other alternatives include rawgit.com - e.g. [https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js] with a fixed version - which is probably a good thing. I've tried this approach for Commons Numbers, which seems to work – not sure if adding {{?config=TeX-AMS-MML_HTMLorMML}} would make any difference there as rawgit caches the file directly from GitHub.

Of course the MathJax javascript is Apache-licensed, so we could easily embed it in the ASF source code - but then in multi-module projects I wonder if we would then need to share it across all modules.",,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2020-01-26 15:25:51.534,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Jan 26 15:25:51 UTC 2020,,,,,,,"0|z0av80:",9223372036854775807,,,,,,,,,,,,,,,,"26/Jan/20 15:25;aherbert;The script I added to commons RNG was:
{code:java}
<script type=""text/javascript"" id=""MathJax-script"" async
  src=""https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"">
</script>
{code}

Looking at [MathJax Getting started|https://docs.mathjax.org/en/v2.7-latest/start.html] it seems the recommendation has changed. 

So should we move to:
{code:java}
<script type=""text/javascript"" async
  src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"">
</script>
{code}

",,,,,,,,,,,,,,,,
Invalid usage of exception in PolynomialSplineFunction,MATH-1419,13080065,Bug,Resolved,MATH,Commons Math,software,issues@commons.apache.org,,http://commons.apache.org/math/,Trivial,Fixed,,hangpark,hangpark,15/Jun/17 11:55,15/Jun/17 13:28,20/Mar/20 20:34,15/Jun/17 12:24,3.6.1,,,,,4.0,,0,easyfix,,,,"In PolynomialSplineFunction constructor, it tests whether length of knots is smaller than 2 or not. If <2, it throws NumberIsTooSmallException like below:
{code:java}
if (knots.length < 2) {
    throw new NumberIsTooSmallException(LocalizedFormats.NOT_ENOUGH_POINTS_IN_SPLINE_PARTITION,
                                                               2, knots.length, false);
        }
{code}

But definition of above exception has parameters of the form:
{code:java}
/**
 * Construct the exception with a specific context.
 *
 * @param specific Specific context pattern.
 * @param wrong Value that is smaller than the minimum.
 * @param min Minimum.
 * @param boundIsAllowed Whether {@code min} is included in the allowed range.
 */
public NumberIsTooSmallException(Localizable specific,
                                 Number wrong,
                                 Number min,
                                 boolean boundIsAllowed) {
    super(specific, wrong, min);

    this.min = min;
    this.boundIsAllowed = boundIsAllowed;
}
{code}

h3. In my opinion, *2, knots.length, false* should be *knots.length, 2, true*

since 2 is the minimum value and knots.length is the wrong value in this case. Moreover, boolean should be set by true because 2 is also acceptable.",,,,,600,600,,0%,600,600,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-06-15 12:24:41.82,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jun 15 13:28:39 UTC 2017,,,,,,,"0|i3gbbj:",9223372036854775807,,,,,,,,,,,,,,,,"15/Jun/17 12:24;erans;Changed in commit 1b53f09c3a9dcd64dd281c1955b062fc28999366
Thanks for the report and fix!
","15/Jun/17 12:39;hangpark;[~erans] Oh, I just made a PR right before.. at [https://github.com/apache/commons-math/pull/62], duplicated.

But, you should also change order of string format position in English and French! I made it, so check above PR. Thanks!","15/Jun/17 13:28;erans;Merged in commit 777af155a678286614d261887790352b43fa7c2a
",,,,,,,,,,,,,,
